resnet50v1.5: Pulling from asulecki/pytorch-off/conv_tests
Digest: sha256:205281eea3cedb2a9ac3d3738680d0d1f51c36b89aed411e2e24fba82bc54293
Status: Image is up to date for gitlab-master.nvidia.com:5005/asulecki/pytorch-off/conv_tests:resnet50v1.5

=============
== PyTorch ==
=============

NVIDIA Release 19.04 (build 6012988)
PyTorch Version 1.1.0a0+9eb0f43

Container image Copyright (c) 2019, NVIDIA CORPORATION.  All rights reserved.

Copyright (c) 2014-2019 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.
NVIDIA modifications are covered by the license terms that apply to the underlying project or file.

NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.

NOTE: Detected MOFED driver 3.4-1.0.0; version automatically upgraded.

=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7fdff3a5c048>}
data : /data/imagenet
data_backend : pytorch
arch : resnet50
model_config : fanin
workers : 5
epochs : 2
start_epoch : 0
batch_size : 128
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.0
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_8GPU_128BS_pytorch_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 8
 ! Weight decay NOT applied to BN parameters 
98
63
Epoch: 0/2  Iteration: 1/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.085
Epoch: 0/2  Iteration: 2/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.026
Epoch: 0/2  Iteration: 3/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.000
Epoch: 0/2  Iteration: 4/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.041
Epoch: 0/2  Iteration: 5/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.112
Epoch: 0/2  Iteration: 6/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.147
Epoch: 0/2  Iteration: 7/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.156
Epoch: 0/2  Iteration: 8/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.196
Epoch: 0/2  Iteration: 9/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.211
Epoch: 0/2  Iteration: 10/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.224
Epoch: 0/2  Iteration: 11/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.255
Epoch: 0/2  Iteration: 12/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.393
Epoch: 0/2  Iteration: 13/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.444
Epoch: 0/2  Iteration: 14/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.335
Epoch: 0/2  Iteration: 15/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.494
Epoch: 0/2  Iteration: 16/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.559
Epoch: 0/2  Iteration: 17/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.351
Epoch: 0/2  Iteration: 18/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.627
Epoch: 0/2  Iteration: 19/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.558
Epoch: 0/2  Iteration: 20/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.706
Epoch: 0/2  Iteration: 21/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.813
Epoch: 0/2  Iteration: 22/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.683
Epoch: 0/2  Iteration: 23/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.479
Epoch: 0/2  Iteration: 24/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 8.543
Epoch: 0/2  Iteration: 25/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 8.271
Epoch: 0/2  Iteration: 26/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.982
Epoch: 0/2  Iteration: 27/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 8.139
Epoch: 0/2  Iteration: 28/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.824
Epoch: 0/2  Iteration: 29/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.461
Epoch: 0/2  Iteration: 30/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.324
Epoch: 0/2  Iteration: 31/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.293
Epoch: 0/2  Iteration: 32/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.264
Epoch: 0/2  Iteration: 33/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.448
Epoch: 0/2  Iteration: 34/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.235
Epoch: 0/2  Iteration: 35/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.371
Epoch: 0/2  Iteration: 36/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.277
Epoch: 0/2  Iteration: 37/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.288
Epoch: 0/2  Iteration: 38/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.135
Epoch: 0/2  Iteration: 39/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.225
Epoch: 0/2  Iteration: 40/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.142
Epoch: 0/2  Iteration: 41/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.176
Epoch: 0/2  Iteration: 42/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.035
Epoch: 0/2  Iteration: 43/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.311
Epoch: 0/2  Iteration: 44/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.187
Epoch: 0/2  Iteration: 45/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.180
Epoch: 0/2  Iteration: 46/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.045
Epoch: 0/2  Iteration: 47/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.095
Epoch: 0/2  Iteration: 48/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.095
Epoch: 0/2  Iteration: 49/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.058
Epoch: 0/2  Iteration: 50/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.036
Epoch: 0/2  Iteration: 51/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.045
Epoch: 0/2  Iteration: 52/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.038
Epoch: 0/2  Iteration: 53/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.247
Epoch: 0/2  Iteration: 54/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.003
Epoch: 0/2  Iteration: 55/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.003
Epoch: 0/2  Iteration: 56/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.005
Epoch: 0/2  Iteration: 57/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.012
Epoch: 0/2  Iteration: 58/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.012
Epoch: 0/2  Iteration: 59/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.005
Epoch: 0/2  Iteration: 60/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.964
Epoch: 0/2  Iteration: 61/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.023
Epoch: 0/2  Iteration: 62/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.079
Epoch: 0/2  Iteration: 63/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.055
Epoch: 0/2  Iteration: 64/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.940
Epoch: 0/2  Iteration: 65/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.957
Epoch: 0/2  Iteration: 66/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.948
Epoch: 0/2  Iteration: 67/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.051
Epoch: 0/2  Iteration: 68/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.029
Epoch: 0/2  Iteration: 69/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.998
Epoch: 0/2  Iteration: 70/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.979
Epoch: 0/2  Iteration: 71/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.999
Epoch: 0/2  Iteration: 72/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.996
Epoch: 0/2  Iteration: 73/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.977
Epoch: 0/2  Iteration: 74/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.962
Epoch: 0/2  Iteration: 75/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.944
Epoch: 0/2  Iteration: 76/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.941
Epoch: 0/2  Iteration: 77/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.986
Epoch: 0/2  Iteration: 78/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.033
Epoch: 0/2  Iteration: 79/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.948
Epoch: 0/2  Iteration: 80/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.958
Epoch: 0/2  Iteration: 81/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 0/2  Iteration: 82/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.099
Epoch: 0/2  Iteration: 83/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.977
Epoch: 0/2  Iteration: 84/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.226
Epoch: 0/2  Iteration: 85/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.928
Epoch: 0/2  Iteration: 86/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.917
Epoch: 0/2  Iteration: 87/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.943
Epoch: 0/2  Iteration: 88/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 0/2  Iteration: 89/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.118
Epoch: 0/2  Iteration: 90/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.940
Epoch: 0/2  Iteration: 91/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.000
Epoch: 0/2  Iteration: 92/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.945
Epoch: 0/2  Iteration: 93/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 0/2  Iteration: 94/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 0/2  Iteration: 95/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.933
Epoch: 0/2  Iteration: 96/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 0/2  Iteration: 97/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.914
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
Epoch: 0/2  Iteration: 98/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 0/2  Iteration: 99/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.958
Epoch: 0/2  Iteration: 100/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.933
Summary Epoch: 0/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.178
Epoch: 1/2  Iteration: 1/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.904
Epoch: 1/2  Iteration: 2/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.916
Epoch: 1/2  Iteration: 3/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.924
Epoch: 1/2  Iteration: 4/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.970
Epoch: 1/2  Iteration: 5/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.933
Epoch: 1/2  Iteration: 6/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.913
Epoch: 1/2  Iteration: 7/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.052
Epoch: 1/2  Iteration: 8/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 1/2  Iteration: 9/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.923
Epoch: 1/2  Iteration: 10/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.943
Epoch: 1/2  Iteration: 11/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 1/2  Iteration: 12/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.974
Epoch: 1/2  Iteration: 13/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.930
Epoch: 1/2  Iteration: 14/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.914
Epoch: 1/2  Iteration: 15/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.917
Epoch: 1/2  Iteration: 16/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.964
Epoch: 1/2  Iteration: 17/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.031
Epoch: 1/2  Iteration: 18/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 19/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.922
Epoch: 1/2  Iteration: 20/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.004
Epoch: 1/2  Iteration: 21/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.973
Epoch: 1/2  Iteration: 22/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 1/2  Iteration: 23/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.922
Epoch: 1/2  Iteration: 24/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 1/2  Iteration: 25/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 26/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.916
Epoch: 1/2  Iteration: 27/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.898
Epoch: 1/2  Iteration: 28/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 29/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.894
Epoch: 1/2  Iteration: 30/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 1/2  Iteration: 31/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.899
Epoch: 1/2  Iteration: 32/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.898
Epoch: 1/2  Iteration: 33/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.905
Epoch: 1/2  Iteration: 34/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.929
Epoch: 1/2  Iteration: 35/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.924
Epoch: 1/2  Iteration: 36/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19660800 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18481152 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 37093376 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 39976960 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 34865152 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. 
  warnings.warn(str(msg))
Epoch: 1/2  Iteration: 37/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.906
Epoch: 1/2  Iteration: 38/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.897
Epoch: 1/2  Iteration: 39/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.918
Epoch: 1/2  Iteration: 40/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.980
Epoch: 1/2  Iteration: 41/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.899
Epoch: 1/2  Iteration: 42/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.900
Epoch: 1/2  Iteration: 43/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.904
Epoch: 1/2  Iteration: 44/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.907
Epoch: 1/2  Iteration: 45/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 46/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.892
Epoch: 1/2  Iteration: 47/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.905
Epoch: 1/2  Iteration: 48/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 1/2  Iteration: 49/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 1/2  Iteration: 50/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.970
Epoch: 1/2  Iteration: 51/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.904
Epoch: 1/2  Iteration: 52/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.904
Epoch: 1/2  Iteration: 53/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 54/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.899
Epoch: 1/2  Iteration: 55/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.899
Epoch: 1/2  Iteration: 56/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.998
Epoch: 1/2  Iteration: 57/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.902
Epoch: 1/2  Iteration: 58/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.939
Epoch: 1/2  Iteration: 59/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.904
Epoch: 1/2  Iteration: 60/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 1/2  Iteration: 61/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.907
Epoch: 1/2  Iteration: 62/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.927
Epoch: 1/2  Iteration: 63/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.898
Epoch: 1/2  Iteration: 64/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.894
Epoch: 1/2  Iteration: 65/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.893
Epoch: 1/2  Iteration: 66/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.922
Epoch: 1/2  Iteration: 67/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 68/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.907
Epoch: 1/2  Iteration: 69/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.902
Epoch: 1/2  Iteration: 70/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 1/2  Iteration: 71/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 72/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.907
Epoch: 1/2  Iteration: 73/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 1/2  Iteration: 74/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.999
Epoch: 1/2  Iteration: 75/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.967
Epoch: 1/2  Iteration: 76/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.952
Epoch: 1/2  Iteration: 77/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 1/2  Iteration: 78/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.925
Epoch: 1/2  Iteration: 79/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.924
Epoch: 1/2  Iteration: 80/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.920
Epoch: 1/2  Iteration: 81/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
Epoch: 1/2  Iteration: 82/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.923
Epoch: 1/2  Iteration: 83/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.945
Epoch: 1/2  Iteration: 84/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.906
Epoch: 1/2  Iteration: 85/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.906
Epoch: 1/2  Iteration: 86/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 1/2  Iteration: 87/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.926
Epoch: 1/2  Iteration: 88/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.897
Epoch: 1/2  Iteration: 89/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 90/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.891
Epoch: 1/2  Iteration: 91/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 1/2  Iteration: 92/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 1/2  Iteration: 93/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.897
Epoch: 1/2  Iteration: 94/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.896
Epoch: 1/2  Iteration: 95/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 1/2  Iteration: 96/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 1/2  Iteration: 97/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.893
Epoch: 1/2  Iteration: 98/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.900
Epoch: 1/2  Iteration: 99/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 1/2  Iteration: 100/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Summary Epoch: 1/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.920
None
Experiment ended
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_128BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_128BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_128BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_128BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_128BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_128BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_128BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_128BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f8142ea3048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-gpu
arch : resnet50
model_config : fanin
workers : 5
epochs : 2
start_epoch : 0
batch_size : 128
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.0
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_8GPU_128BS_dali-gpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 8
 ! Weight decay NOT applied to BN parameters 
98
63
Epoch: 0/2  Iteration: 1/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.103
Epoch: 0/2  Iteration: 2/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.031
Epoch: 0/2  Iteration: 3/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.043
Epoch: 0/2  Iteration: 4/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.032
Epoch: 0/2  Iteration: 5/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.136
Epoch: 0/2  Iteration: 6/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.254
Epoch: 0/2  Iteration: 7/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.293
Epoch: 0/2  Iteration: 8/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.280
Epoch: 0/2  Iteration: 9/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.387
Epoch: 0/2  Iteration: 10/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.205
Epoch: 0/2  Iteration: 11/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.451
Epoch: 0/2  Iteration: 12/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.309
Epoch: 0/2  Iteration: 13/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.303
Epoch: 0/2  Iteration: 14/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.419
Epoch: 0/2  Iteration: 15/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.358
Epoch: 0/2  Iteration: 16/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.444
Epoch: 0/2  Iteration: 17/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.380
Epoch: 0/2  Iteration: 18/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.439
Epoch: 0/2  Iteration: 19/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.369
Epoch: 0/2  Iteration: 20/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.588
Epoch: 0/2  Iteration: 21/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.457
Epoch: 0/2  Iteration: 22/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.666
Epoch: 0/2  Iteration: 23/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.739
Epoch: 0/2  Iteration: 24/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.763
Epoch: 0/2  Iteration: 25/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.318
Epoch: 0/2  Iteration: 26/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.517
Epoch: 0/2  Iteration: 27/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.632
Epoch: 0/2  Iteration: 28/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.297
Epoch: 0/2  Iteration: 29/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.394
Epoch: 0/2  Iteration: 30/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.233
Epoch: 0/2  Iteration: 31/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.361
Epoch: 0/2  Iteration: 32/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.610
Epoch: 0/2  Iteration: 33/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.186
Epoch: 0/2  Iteration: 34/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.460
Epoch: 0/2  Iteration: 35/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.340
Epoch: 0/2  Iteration: 36/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.567
Epoch: 0/2  Iteration: 37/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.229
Epoch: 0/2  Iteration: 38/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.592
Epoch: 0/2  Iteration: 39/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.189
Epoch: 0/2  Iteration: 40/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.163
Epoch: 0/2  Iteration: 41/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.122
Epoch: 0/2  Iteration: 42/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.140
Epoch: 0/2  Iteration: 43/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.079
Epoch: 0/2  Iteration: 44/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.087
Epoch: 0/2  Iteration: 45/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.176
Epoch: 0/2  Iteration: 46/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.021
Epoch: 0/2  Iteration: 47/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.103
Epoch: 0/2  Iteration: 48/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.048
Epoch: 0/2  Iteration: 49/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.119
Epoch: 0/2  Iteration: 50/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.002
Epoch: 0/2  Iteration: 51/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.017
Epoch: 0/2  Iteration: 52/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.998
Epoch: 0/2  Iteration: 53/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.969
Epoch: 0/2  Iteration: 54/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.006
Epoch: 0/2  Iteration: 55/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.989
Epoch: 0/2  Iteration: 56/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.975
Epoch: 0/2  Iteration: 57/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.001
Epoch: 0/2  Iteration: 58/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.951
Epoch: 0/2  Iteration: 59/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.972
Epoch: 0/2  Iteration: 60/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.039
Epoch: 0/2  Iteration: 61/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.949
Epoch: 0/2  Iteration: 62/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.978
Epoch: 0/2  Iteration: 63/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.946
Epoch: 0/2  Iteration: 64/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.003
Epoch: 0/2  Iteration: 65/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.944
Epoch: 0/2  Iteration: 66/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.969
Epoch: 0/2  Iteration: 67/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.961
Epoch: 0/2  Iteration: 68/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.957
Epoch: 0/2  Iteration: 69/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.951
Epoch: 0/2  Iteration: 70/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.995
Epoch: 0/2  Iteration: 71/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.933
Epoch: 0/2  Iteration: 72/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.939
Epoch: 0/2  Iteration: 73/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.933
Epoch: 0/2  Iteration: 74/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.936
Epoch: 0/2  Iteration: 75/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.932
Epoch: 0/2  Iteration: 76/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.936
Epoch: 0/2  Iteration: 77/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.937
Epoch: 0/2  Iteration: 78/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.938
Epoch: 0/2  Iteration: 79/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.955
Epoch: 0/2  Iteration: 80/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.970
Epoch: 0/2  Iteration: 81/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.959
Epoch: 0/2  Iteration: 82/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.954
Epoch: 0/2  Iteration: 83/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.931
Epoch: 0/2  Iteration: 84/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.956
Epoch: 0/2  Iteration: 85/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.935
Epoch: 0/2  Iteration: 86/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.932
Epoch: 0/2  Iteration: 87/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.933
Epoch: 0/2  Iteration: 88/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.924
Epoch: 0/2  Iteration: 89/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.938
Epoch: 0/2  Iteration: 90/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.958
Epoch: 0/2  Iteration: 91/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.927
Epoch: 0/2  Iteration: 92/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.927
Epoch: 0/2  Iteration: 93/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.930
Epoch: 0/2  Iteration: 94/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.985
Epoch: 0/2  Iteration: 95/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.922
Epoch: 0/2  Iteration: 96/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.001
Epoch: 0/2  Iteration: 97/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.914
Epoch: 0/2  Iteration: 98/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.918
Epoch: 0/2  Iteration: 99/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.002
Epoch: 0/2  Iteration: 100/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.948
Summary Epoch: 0/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.133
Epoch: 1/2  Iteration: 1/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.941
Epoch: 1/2  Iteration: 2/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.970
Epoch: 1/2  Iteration: 3/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.071
Epoch: 1/2  Iteration: 4/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.961
Epoch: 1/2  Iteration: 5/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.953
Epoch: 1/2  Iteration: 6/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.992
Epoch: 1/2  Iteration: 7/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.936
Epoch: 1/2  Iteration: 8/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.022
Epoch: 1/2  Iteration: 9/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.929
Epoch: 1/2  Iteration: 10/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 1/2  Iteration: 11/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.933
Epoch: 1/2  Iteration: 12/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.958
Epoch: 1/2  Iteration: 13/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.931
Epoch: 1/2  Iteration: 14/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.944
Epoch: 1/2  Iteration: 15/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.937
Epoch: 1/2  Iteration: 16/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.954
Epoch: 1/2  Iteration: 17/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.925
Epoch: 1/2  Iteration: 18/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.937
Epoch: 1/2  Iteration: 19/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.935
Epoch: 1/2  Iteration: 20/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.931
Epoch: 1/2  Iteration: 21/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.986
Epoch: 1/2  Iteration: 22/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 1/2  Iteration: 23/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.921
Epoch: 1/2  Iteration: 24/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 1/2  Iteration: 25/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.923
Epoch: 1/2  Iteration: 26/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.921
Epoch: 1/2  Iteration: 27/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.918
Epoch: 1/2  Iteration: 28/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.922
Epoch: 1/2  Iteration: 29/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.916
Epoch: 1/2  Iteration: 30/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 1/2  Iteration: 31/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.923
Epoch: 1/2  Iteration: 32/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.108
Epoch: 1/2  Iteration: 33/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.917
Epoch: 1/2  Iteration: 34/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.935
Epoch: 1/2  Iteration: 35/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.916
Epoch: 1/2  Iteration: 36/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.917
Epoch: 1/2  Iteration: 37/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.914
Epoch: 1/2  Iteration: 38/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.926
Epoch: 1/2  Iteration: 39/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 1/2  Iteration: 40/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
Epoch: 1/2  Iteration: 41/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 1/2  Iteration: 42/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.945
Epoch: 1/2  Iteration: 43/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 44/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
Epoch: 1/2  Iteration: 45/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
Epoch: 1/2  Iteration: 46/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 1/2  Iteration: 47/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
Epoch: 1/2  Iteration: 48/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.913
Epoch: 1/2  Iteration: 49/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 1/2  Iteration: 50/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 1/2  Iteration: 51/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 1/2  Iteration: 52/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.924
Epoch: 1/2  Iteration: 53/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.905
Epoch: 1/2  Iteration: 54/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.906
Epoch: 1/2  Iteration: 55/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.913
Epoch: 1/2  Iteration: 56/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
Epoch: 1/2  Iteration: 57/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.947
Epoch: 1/2  Iteration: 58/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 59/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 60/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.977
Epoch: 1/2  Iteration: 61/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.917
Epoch: 1/2  Iteration: 62/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 63/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.975
Epoch: 1/2  Iteration: 64/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.930
Epoch: 1/2  Iteration: 65/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.922
Epoch: 1/2  Iteration: 66/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 67/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.906
Epoch: 1/2  Iteration: 68/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 1/2  Iteration: 69/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 1/2  Iteration: 70/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 1/2  Iteration: 71/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 1/2  Iteration: 72/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 1/2  Iteration: 73/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.916
Epoch: 1/2  Iteration: 74/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 1/2  Iteration: 75/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 76/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 77/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 1/2  Iteration: 78/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 1/2  Iteration: 79/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 80/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.929
Epoch: 1/2  Iteration: 81/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.899
Epoch: 1/2  Iteration: 82/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 1/2  Iteration: 83/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.904
Epoch: 1/2  Iteration: 84/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
Epoch: 1/2  Iteration: 85/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.902
Epoch: 1/2  Iteration: 86/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.958
Epoch: 1/2  Iteration: 87/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.907
Epoch: 1/2  Iteration: 88/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.923
Epoch: 1/2  Iteration: 89/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.899
Epoch: 1/2  Iteration: 90/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 91/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.906
Epoch: 1/2  Iteration: 92/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
Epoch: 1/2  Iteration: 93/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.905
Epoch: 1/2  Iteration: 94/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.924
Epoch: 1/2  Iteration: 95/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.927
Epoch: 1/2  Iteration: 96/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.925
Epoch: 1/2  Iteration: 97/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.894
Epoch: 1/2  Iteration: 98/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.899
Epoch: 1/2  Iteration: 99/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.902
Epoch: 1/2  Iteration: 100/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Summary Epoch: 1/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.926
None
Experiment ended
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '8', 'main.py', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_128BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
Job ended sucessfully
train.total_ips
[[124.45806131288346, 1713.8866160597386, 2839.142853932094, 2946.6627990422417, 2926.3709222124485, 2939.3364891804904, 2949.7571126087796, 2932.701196100536, 2945.731123686671, 2947.0611133868956, 2937.3162340788726, 2929.922338389165, 2939.972288068824, 2938.805526228098, 2947.0449360874063, 2934.9838359403293, 2931.212081463065, 2946.270655606806, 2936.179680524811, 2935.3168088660227, 2927.4879208679336, 2942.4436485208885, 2944.886859945051, 2941.033235640527, 2928.675666645301, 2934.8875686919255, 2944.0531702107533, 2924.7468123762337, 2944.9151288881576, 2932.93150340687, 2933.6607146028427, 2935.5956816682788, 2935.021943470842, 2944.0814231503214, 2935.868586923904, 2927.697453054235, 2933.44832447259, 2926.3669344591017, 2938.105913538991, 2933.5224571562444, 2933.923239239866, 2935.8966829925184, 2933.786961044887, 2930.170200863162, 2932.1626184991856, 2931.8023424562343, 2947.866158307452, 2932.108571448077, 2935.3007602452685, 2937.9873340657264, 2929.023189583919, 2931.850374146549, 2930.8000401239474, 2922.8281050946744, 2921.5039949065454, 2931.592222313989, 2930.72604497044, 2938.785417765726, 2947.702281861507, 2938.8799299316424, 2923.691609792093, 2934.821388621826, 2939.4310367955236, 2932.4509030925133, 2938.4034092580596, 2923.9165230793737, 2928.174500076017, 2932.3968454133756, 2934.550683048348, 2945.723042313799, 2937.6638014821806, 2935.9649185408794, 2934.94773498211, 2931.2921029229196, 2923.194136960345, 2926.2353446954344, 2921.2854134585564, 2916.249230871602, 2929.194984252473, 2925.529746972105, 2926.837564389213, 2944.277190555482, 2934.4624638740665, 2920.149316972214, 2928.004821189236, 2925.366351968865, 2925.6234084351236, 2924.2848186589176, 2920.361771323393, 2928.8554095928075, 2925.8964558574576, 2934.201847297371, 2930.658052718129, 2930.5100804855883, 2928.3741474752724, 2932.108571448077, 2929.5006687770147, 2919.875356064345, 2930.166202748578, 2917.5725448558965], [611.2317639144519, 2772.2290220702093, 2881.3700371461405, 2921.662983778695, 2918.5797016162737, 2934.251962274592, 2926.7358476423074, 2931.2500911117268, 2836.7182427139705, 2933.738865881006, 2930.8680389648052, 2939.9783254522604, 2918.5162381500204, 2929.356809288894, 2924.444110349411, 2910.094205107983, 2927.0071080131775, 2923.908560956299, 2924.744820710756, 2923.621953402761, 2928.4360436970987, 2927.9688917127282, 2928.6696755936655, 2941.4239860399434, 2920.0440940213766, 2925.394247384664, 2920.4749605613883, 2924.7189293063834, 2927.541797708389, 2921.1383861590716, 2929.636549046036, 2895.263660423096, 2921.977037643787, 2930.07025127164, 2933.821029406742, 2893.500384680163, 2918.105775515445, 2918.6372177666512, 2918.916897565285, 2919.5756461352207, 2923.5025501712935, 2901.88532499674, 2907.289124151329, 2936.8864089845474, 2926.408806411303, 2924.758762426063, 2914.9409650394455, 2925.647322961227, 2914.1775280258485, 2922.7386003820343, 2900.5154758367325, 2928.1605257775536, 2916.3759634469043, 2920.010344869785, 2929.1969819834258, 2922.227534056627, 2922.7207000973112, 2920.8026630850577, 2906.793282447708, 2918.621351015987, 2912.6735807305, 2916.3422990322692, 2902.618794380163, 2930.220178216052, 2911.484960828536, 2926.9412828618956, 2927.0011237861713, 2923.5702108049713, 2912.452368665707, 2916.13438898881, 2913.254422313189, 2933.6166311032666, 2916.2076491452967, 2918.0443152055386, 2916.173988616311, 2918.9704593862434, 2932.7232239306572, 2926.033995391887, 2910.7489769944036, 2913.4441350464563, 2923.315504716477, 2918.524170932365, 2915.3070028311613, 2910.0449119221958, 2932.6771661177954, 2917.8183221363893, 2923.1264937324154, 2919.9309381785747, 2919.7264858257927, 2923.9205041571727, 2920.760951406872, 2917.584436351681, 2928.4400370915837, 2919.1212365478123, 2915.350537765786, 2921.7842244219482, 2916.2927939519905, 2918.2306867032985, 2920.931778211519, 2925.852605391103], []]
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '8', 'main.py', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
Job ended sucessfully
train.total_ips
[[133.0857381417303, 1077.7434855618912, 2058.7267892964564, 2909.893099401892, 2909.7767862405467, 2912.9600212691785, 2929.236937174721, 2922.108244694241, 2920.4729747096676, 2834.7186683650907, 2911.8994854814096, 2923.749327600608, 2898.4269391771104, 2907.0667615165053, 2897.914562485789, 2924.4799533713826, 2913.637825615922, 2918.02448985138, 2912.2687091804632, 2911.5027237501795, 2907.8225395537966, 2914.153800641865, 2901.963753217015, 2910.8061849172327, 2896.847367018855, 2919.226392998153, 2909.550100869688, 2925.651308753588, 2919.0696531344047, 2917.729123981674, 2877.497593804121, 2915.6850085808005, 2923.5542903741157, 2888.444852140088, 2913.799913026311, 2898.7242789410634, 2918.381387447807, 2919.7900019374774, 2923.291628296045, 2913.898755664167, 2900.6016656806573, 2912.3852216514942, 2920.516664071388, 2918.9526052275137, 2898.5032244828544, 2894.8499559871616, 2912.2667344731603, 2915.5504193808533, 2907.76151164129, 2917.895631615419, 2908.933301274996, 2896.9509248055083, 2915.8631604531265, 2909.605290576601, 2895.16607796718, 2803.536396641736, 2916.71463108542, 2904.7507042129687, 2910.0074502178286, 2914.780728775382, 2876.472350494295, 2915.8849360638987, 2915.117047422087, 2904.2459086673634, 2906.7755769435107, 2874.6972482345077, 2890.9120314684396, 2920.455102165709, 2909.851698736254, 2910.340696088323, 2914.219051877565, 2915.6988640567965, 2912.2311901996404, 2921.4543144325025, 2882.2188865625167, 2890.478171507946, 2905.0768522119674, 2911.1692117280004, 2906.8975525698997, 2891.937859559156, 2899.5814282251927, 2904.5464078365867, 2840.7765968493927, 2908.509772531811, 2894.4519746445426, 2912.851364777899, 2902.9169948666304, 2918.2762918651833, 2903.187782589798, 2903.666690328857, 2914.545351892467, 2899.96711500027, 2910.135612674601, 2902.0166946622758, 2878.2843659382775, 2907.5213621519747, 2899.1782309545492, 2898.4523671661896, 2908.084398059186, 2908.665380387929], [2527.8119081741056, 2896.3863316498873, 2904.342140195252, 2903.4703975587677, 2913.6417787528435, 2892.424749916156, 2918.4150989550703, 2911.7632715045015, 2903.7059520678667, 2902.438334372903, 2894.6997246812944, 2904.75463327109, 2905.7411631307014, 2911.836312197331, 2894.212068181282, 2898.4386751166303, 2918.918881301379, 2911.0725272639775, 2898.7516685665614, 2903.658838108463, 2894.2140184799837, 2910.186880818301, 2909.15792004801, 2903.935654516246, 2899.313269977737, 2903.333008409928, 2909.012110929367, 2907.5115208059588, 2893.7928149845034, 2899.1019101143315, 2913.266278635184, 2895.2753707598554, 2894.4129627557986, 2888.5011866819914, 2912.0495330176045, 2889.3464685795475, 2906.5532928555767, 2851.2961686121353, 2884.921516103291, 2910.411693235528, 2907.635526634686, 2912.3279516448165, 2906.830661442679, 2895.7419095591226, 2916.2056690926697, 2908.1690691689073, 2904.4128449735017, 2888.5575234213693, 2900.9229638675306, 2884.156289556723, 2894.0989553537197, 2907.1297280137755, 2903.639207743277, 2902.5677925381474, 2920.4968051085625, 2914.804466369551, 2898.5208293544447, 2903.156384322701, 2902.5893700218016, 2899.8633414647156, 2900.9954617143358, 2901.603018500816, 2904.4069527771617, 2906.8188574456753, 2914.820291647127, 2915.7542872776426, 2905.6546675858394, 2839.706001246968, 2913.4441350464563, 2897.0974814958713, 2893.354191690385, 2904.740881614169, 2894.227670644491, 2898.935583743428, 2900.5664055799352, 2908.1316557450086, 2901.559893178546, 2903.790368402193, 2903.0249114553762, 2908.1533160309873, 2904.7192721306465, 2894.013151520093, 2890.8517113030134, 2903.39385057176, 2915.033949714433, 2892.853349067342, 2902.0049297297296, 2907.1749868685392, 2901.501087986748, 2909.0180218255905, 2900.777979043999, 2898.892537674078, 2909.427902540536, 2910.729250645855, 2903.921910612614, 2900.470424093199, 2898.4445431220297, 2906.301543092085, 2916.320516589882, 2908.6496218726697], []]=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7fe5aedfe048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-cpu
arch : resnet50
model_config : fanin
workers : 5
epochs : 2
start_epoch : 0
batch_size : 128
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.0
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_8GPU_128BS_dali-cpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 8
 ! Weight decay NOT applied to BN parameters 
98
63
Epoch: 0/2  Iteration: 1/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.070
Epoch: 0/2  Iteration: 2/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.030
Epoch: 0/2  Iteration: 3/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.043
Epoch: 0/2  Iteration: 4/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.084
Epoch: 0/2  Iteration: 5/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.121
Epoch: 0/2  Iteration: 6/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.184
Epoch: 0/2  Iteration: 7/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.249
Epoch: 0/2  Iteration: 8/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.257
Epoch: 0/2  Iteration: 9/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.283
Epoch: 0/2  Iteration: 10/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.249
Epoch: 0/2  Iteration: 11/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.340
Epoch: 0/2  Iteration: 12/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.433
Epoch: 0/2  Iteration: 13/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.371
Epoch: 0/2  Iteration: 14/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.518
Epoch: 0/2  Iteration: 15/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.372
Epoch: 0/2  Iteration: 16/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.453
Epoch: 0/2  Iteration: 17/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.361
Epoch: 0/2  Iteration: 18/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.400
Epoch: 0/2  Iteration: 19/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.587
Epoch: 0/2  Iteration: 20/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.516
Epoch: 0/2  Iteration: 21/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.546
Epoch: 0/2  Iteration: 22/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.699
Epoch: 0/2  Iteration: 23/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.427
Epoch: 0/2  Iteration: 24/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.644
Epoch: 0/2  Iteration: 25/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.629
Epoch: 0/2  Iteration: 26/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.377
Epoch: 0/2  Iteration: 27/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.317
Epoch: 0/2  Iteration: 28/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.441
Epoch: 0/2  Iteration: 29/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.660
Epoch: 0/2  Iteration: 30/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.601
Epoch: 0/2  Iteration: 31/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.570
Epoch: 0/2  Iteration: 32/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.390
Epoch: 0/2  Iteration: 33/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.138
Epoch: 0/2  Iteration: 34/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.160
Epoch: 0/2  Iteration: 35/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.175
Epoch: 0/2  Iteration: 36/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.154
Epoch: 0/2  Iteration: 37/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.117
Epoch: 0/2  Iteration: 38/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.337
Epoch: 0/2  Iteration: 39/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.121
Epoch: 0/2  Iteration: 40/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.205
Epoch: 0/2  Iteration: 41/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.067
Epoch: 0/2  Iteration: 42/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.057
Epoch: 0/2  Iteration: 43/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.106
Epoch: 0/2  Iteration: 44/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.086
Epoch: 0/2  Iteration: 45/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.013
Epoch: 0/2  Iteration: 46/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.126
Epoch: 0/2  Iteration: 47/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.027
Epoch: 0/2  Iteration: 48/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.074
Epoch: 0/2  Iteration: 49/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.045
Epoch: 0/2  Iteration: 50/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.990
Epoch: 0/2  Iteration: 51/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.046
Epoch: 0/2  Iteration: 52/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.002
Epoch: 0/2  Iteration: 53/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.015
Epoch: 0/2  Iteration: 54/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.998
Epoch: 0/2  Iteration: 55/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.095
Epoch: 0/2  Iteration: 56/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.977
Epoch: 0/2  Iteration: 57/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.005
Epoch: 0/2  Iteration: 58/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.008
Epoch: 0/2  Iteration: 59/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.021
Epoch: 0/2  Iteration: 60/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.035
Epoch: 0/2  Iteration: 61/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.982
Epoch: 0/2  Iteration: 62/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.008
Epoch: 0/2  Iteration: 63/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.986
Epoch: 0/2  Iteration: 64/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.963
Epoch: 0/2  Iteration: 65/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.959
Epoch: 0/2  Iteration: 66/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.045
Epoch: 0/2  Iteration: 67/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.008
Epoch: 0/2  Iteration: 68/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.980
Epoch: 0/2  Iteration: 69/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.938
Epoch: 0/2  Iteration: 70/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.123
Epoch: 0/2  Iteration: 71/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.957
Epoch: 0/2  Iteration: 72/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.945
Epoch: 0/2  Iteration: 73/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.943
Epoch: 0/2  Iteration: 74/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.924
Epoch: 0/2  Iteration: 75/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.963
Epoch: 0/2  Iteration: 76/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.044
Epoch: 0/2  Iteration: 77/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.993
Epoch: 0/2  Iteration: 78/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.949
Epoch: 0/2  Iteration: 79/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.959
Epoch: 0/2  Iteration: 80/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.929
Epoch: 0/2  Iteration: 81/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.046
Epoch: 0/2  Iteration: 82/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.924
Epoch: 0/2  Iteration: 83/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.944
Epoch: 0/2  Iteration: 84/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.930
Epoch: 0/2  Iteration: 85/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.942
Epoch: 0/2  Iteration: 86/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.970
Epoch: 0/2  Iteration: 87/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.923
Epoch: 0/2  Iteration: 88/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.944
Epoch: 0/2  Iteration: 89/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.958
Epoch: 0/2  Iteration: 90/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.099
Epoch: 0/2  Iteration: 91/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.975
Epoch: 0/2  Iteration: 92/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.957
Epoch: 0/2  Iteration: 93/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.950
Epoch: 0/2  Iteration: 94/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.011
Epoch: 0/2  Iteration: 95/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.923
Epoch: 0/2  Iteration: 96/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.917
Epoch: 0/2  Iteration: 97/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.920
Epoch: 0/2  Iteration: 98/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.921
Epoch: 0/2  Iteration: 99/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 0/2  Iteration: 100/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.030
Summary Epoch: 0/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.132
Epoch: 1/2  Iteration: 1/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.925
Epoch: 1/2  Iteration: 2/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.930
Epoch: 1/2  Iteration: 3/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.943
Epoch: 1/2  Iteration: 4/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.981
Epoch: 1/2  Iteration: 5/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
Epoch: 1/2  Iteration: 6/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.934
Epoch: 1/2  Iteration: 7/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.928
Epoch: 1/2  Iteration: 8/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.923
Epoch: 1/2  Iteration: 9/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.924
Epoch: 1/2  Iteration: 10/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.937
Epoch: 1/2  Iteration: 11/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.916
Epoch: 1/2  Iteration: 12/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.913
Epoch: 1/2  Iteration: 13/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.927
Epoch: 1/2  Iteration: 14/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.925
Epoch: 1/2  Iteration: 15/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.933
Epoch: 1/2  Iteration: 16/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.907
Epoch: 1/2  Iteration: 17/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.935
Epoch: 1/2  Iteration: 18/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.897
Epoch: 1/2  Iteration: 19/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.930
Epoch: 1/2  Iteration: 20/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.934
Epoch: 1/2  Iteration: 21/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.914
Epoch: 1/2  Iteration: 22/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 23/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.904
Epoch: 1/2  Iteration: 24/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 1/2  Iteration: 25/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 1/2  Iteration: 26/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.896
Epoch: 1/2  Iteration: 27/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 1/2  Iteration: 28/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.913
Epoch: 1/2  Iteration: 29/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.895
Epoch: 1/2  Iteration: 30/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.913
Epoch: 1/2  Iteration: 31/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.884
Epoch: 1/2  Iteration: 32/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.892
Epoch: 1/2  Iteration: 33/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 34/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.895
Epoch: 1/2  Iteration: 35/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.960
Epoch: 1/2  Iteration: 36/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 1/2  Iteration: 37/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.877
Epoch: 1/2  Iteration: 38/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.892
Epoch: 1/2  Iteration: 39/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.898
Epoch: 1/2  Iteration: 40/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.884
Epoch: 1/2  Iteration: 41/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.896
Epoch: 1/2  Iteration: 42/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.908
Epoch: 1/2  Iteration: 43/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.946
Epoch: 1/2  Iteration: 44/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.916
Epoch: 1/2  Iteration: 45/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.907
Epoch: 1/2  Iteration: 46/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.886
Epoch: 1/2  Iteration: 47/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.887
Epoch: 1/2  Iteration: 48/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.895
Epoch: 1/2  Iteration: 49/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 1/2  Iteration: 50/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.905
Epoch: 1/2  Iteration: 51/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.887
Epoch: 1/2  Iteration: 52/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.945
Epoch: 1/2  Iteration: 53/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 1/2  Iteration: 54/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.893
Epoch: 1/2  Iteration: 55/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.887
Epoch: 1/2  Iteration: 56/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.894
Epoch: 1/2  Iteration: 57/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.882
Epoch: 1/2  Iteration: 58/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.883
Epoch: 1/2  Iteration: 59/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.953
Epoch: 1/2  Iteration: 60/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.896
Epoch: 1/2  Iteration: 61/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 62/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.883
Epoch: 1/2  Iteration: 63/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.875
Epoch: 1/2  Iteration: 64/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.893
Epoch: 1/2  Iteration: 65/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.898
Epoch: 1/2  Iteration: 66/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.889
Epoch: 1/2  Iteration: 67/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 1/2  Iteration: 68/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.879
Epoch: 1/2  Iteration: 69/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.881
Epoch: 1/2  Iteration: 70/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.890
Epoch: 1/2  Iteration: 71/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.888
Epoch: 1/2  Iteration: 72/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.878
Epoch: 1/2  Iteration: 73/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.884
Epoch: 1/2  Iteration: 74/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.878
Epoch: 1/2  Iteration: 75/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.877
Epoch: 1/2  Iteration: 76/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.874
Epoch: 1/2  Iteration: 77/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.879
Epoch: 1/2  Iteration: 78/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.888
Epoch: 1/2  Iteration: 79/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.880
Epoch: 1/2  Iteration: 80/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.854
Epoch: 1/2  Iteration: 81/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.876
Epoch: 1/2  Iteration: 82/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.895
Epoch: 1/2  Iteration: 83/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.871
Epoch: 1/2  Iteration: 84/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.874
Epoch: 1/2  Iteration: 85/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.864
Epoch: 1/2  Iteration: 86/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 1/2  Iteration: 87/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.864
Epoch: 1/2  Iteration: 88/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.875
Epoch: 1/2  Iteration: 89/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.860
Epoch: 1/2  Iteration: 90/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.869
Epoch: 1/2  Iteration: 91/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.868
Epoch: 1/2  Iteration: 92/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.858
Epoch: 1/2  Iteration: 93/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.868
Epoch: 1/2  Iteration: 94/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.868
Epoch: 1/2  Iteration: 95/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.866
Epoch: 1/2  Iteration: 96/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.855
Epoch: 1/2  Iteration: 97/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.866
Epoch: 1/2  Iteration: 98/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.863
Epoch: 1/2  Iteration: 99/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.895
Epoch: 1/2  Iteration: 100/1251;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.848
Summary Epoch: 1/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.898
None
Experiment ended
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f26d5c77048>}
data : /data/imagenet
data_backend : pytorch
arch : resnet50
model_config : fanin
workers : 5
epochs : 2
start_epoch : 0
batch_size : 256
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.0
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 8
 ! Weight decay NOT applied to BN parameters 
98
63
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 4; 15.75 GiB total capacity; 14.17 GiB already allocated; 241.94 MiB free; 314.23 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 1; 15.75 GiB total capacity; 14.17 GiB already allocated; 241.94 MiB free; 314.23 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 15.75 GiB total capacity; 14.17 GiB already allocated; 241.94 MiB free; 314.23 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 2; 15.75 GiB total capacity; 14.17 GiB already allocated; 241.94 MiB free; 314.23 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 5; 15.75 GiB total capacity; 14.17 GiB already allocated; 241.94 MiB free; 314.23 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 6; 15.75 GiB total capacity; 14.17 GiB already allocated; 241.94 MiB free; 314.23 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 3; 15.75 GiB total capacity; 14.17 GiB already allocated; 241.94 MiB free; 314.23 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 7; 15.75 GiB total capacity; 14.17 GiB already allocated; 241.94 MiB free; 314.23 MiB cached)
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']

['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '8', 'main.py', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '128', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_128BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
Job ended sucessfully
train.total_ips
[[126.48018415890625, 1673.3343265625438, 2948.432785174659, 2959.50123996811, 2950.334600029126, 2956.8423684659824, 2948.1797998380034, 2956.3070976001763, 2954.172014595578, 2941.0372634655337, 2946.7436663396293, 2952.8335702951617, 2954.6800879187404, 2947.4008777076665, 2953.593024103428, 2943.8433082059487, 2940.7573558863864, 2938.005421841278, 2953.8570968762465, 2957.5753729534385, 2946.4080960639253, 2949.238579767726, 2940.0185753088585, 2937.509093694601, 2941.8128253056734, 2947.28963671548, 2936.6012673633427, 2949.832071889912, 2946.590022269392, 2941.5488869286023, 2949.631513704731, 2950.0184736440115, 2942.4214744281417, 2945.1534172611305, 2953.623491629044, 2938.719061792256, 2925.2368445069833, 2934.8454537565285, 2930.0742491243823, 2943.37727942149, 2958.942582298155, 2948.742498328232, 2932.6411218820394, 2943.4438459282164, 2938.9181387029384, 2938.8819408948366, 2925.7928114187853, 2934.711095137294, 2941.5186679989783, 2937.4849848576455, 2928.74556405887, 2949.264907119765, 2949.5160531809693, 2940.711045381097, 2942.7682348531926, 2949.378322625303, 2942.060688426893, 2943.581022770263, 2951.443604320754, 2938.2365630237728, 2940.682857091995, 2927.785265936271, 2901.2208159956767, 2940.964764303332, 2940.3647695749687, 2954.159822982919, 2942.901315784966, 2932.9855808004413, 2930.256162965783, 2937.509093694601, 2942.2561871768717, 2948.6291317165064, 2933.981361732941, 2934.9357015267246, 2941.3051385916556, 2912.0357122032515, 2939.5436972144275, 2945.222083779349, 2944.7132197718943, 2947.6537293765614, 2943.0424753813822, 2940.3828866359095, 2937.623616074635, 2941.6919316207236, 2948.309322906513, 2950.1846341949267, 2949.998211442646, 2938.7834069346236, 2926.2313573115803, 2939.0026037229472, 2937.0290005614247, 2940.398990877505, 2941.077542322394, 2942.7480721256256, 2939.0951186014317, 2926.54041177657, 2947.4494218631726, 2941.5750771698476, 2946.003896025505, 2929.8044185470653], [2100.7092557123096, 2945.620008696332, 2931.7363014516814, 2933.7368619500653, 2935.8605595744984, 2946.129186176204, 2944.6264073638845, 2929.7624493682715, 2941.6838723950145, 2928.841428794515, 2927.3861589129533, 2933.498413713168, 2956.0120691553793, 2942.6412142820927, 2929.694501818539, 2933.5705452248008, 2924.822497674425, 2940.5519899712376, 2942.58879629046, 2939.157468870014, 2941.3776545365017, 2933.0336512688627, 2945.49678187453, 2949.127200017578, 2939.6221622505836, 2938.02551963088, 2923.8866653414334, 2929.76045086594, 2949.8888003648412, 2941.5992531910942, 2934.259980829811, 2950.164369710957, 2945.1736129635256, 2940.2218539215464, 2928.9892325580604, 2925.438084112945, 2926.406812481646, 2937.342349002698, 2940.4996463842535, 2926.075857816838, 2937.408642817964, 2929.520650378999, 2937.923023778547, 2934.8875686919255, 2943.3631596404616, 2942.4476802100216, 2928.018794001572, 2929.8304000698527, 2926.574312045381, 2942.2521560124815, 2938.853787660552, 2945.117065694782, 2945.06052059741, 2924.7189293063834, 2938.0134609241236, 2936.6414248049973, 2938.0878245260715, 2937.975275672422, 2941.5327700888697, 2932.7953173247242, 2941.6012678774696, 2945.1695738008884, 2943.3853479286154, 2942.3247186616054, 2938.162191892526, 2929.924337112362, 2934.743179659581, 2926.6520862179873, 2927.4480133757106, 2946.875085164995, 2937.9973828024263, 2930.5860643601177, 2931.3421185540697, 2931.2400884770336, 2937.241909529525, 2949.1555504285407, 2947.851995426162, 2939.5597922649636, 2928.4180735566947, 2935.543514381539, 2932.975566317848, 2935.320821048632, 2934.0515126363284, 2936.6695356676446, 2932.957540421516, 2926.3689283344165, 2942.51622061572, 2943.08280918194, 2942.522268451879, 2949.734828151742, 2937.404624925795, 2922.8499848582287, 2928.6077694953347, 2928.1505442174553, 2945.882657638502, 2946.907436212176, 2932.899458484987, 2934.1657655737413, 2919.863445886598, 2928.9732530536226], []]
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '8', 'main.py', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
CMD: "/opt/conda/bin/python multiproc.py --nproc_per_node 8 main.py -p 1 -j 5 --training-only  --workspace /data/workspace --epochs 2 --prof 100  -b 256 --data-backend pytorch --raport-file /data/workspace/./raport_8GPU_256BS_pytorch_trainingbench.json --no-checkpoints /data/imagenet --arch resnet50 -c fanin --label-smoothing 0.1 --mixup 0.0" exited with status 1
train.total_ips
[[126.48018415890625, 1673.3343265625438, 2948.432785174659, 2959.50123996811, 2950.334600029126, 2956.8423684659824, 2948.1797998380034, 2956.3070976001763, 2954.172014595578, 2941.0372634655337, 2946.7436663396293, 2952.8335702951617, 2954.6800879187404, 2947.4008777076665, 2953.593024103428, 2943.8433082059487, 2940.7573558863864, 2938.005421841278, 2953.8570968762465, 2957.5753729534385, 2946.4080960639253, 2949.238579767726, 2940.0185753088585, 2937.509093694601, 2941.8128253056734, 2947.28963671548, 2936.6012673633427, 2949.832071889912, 2946.590022269392, 2941.5488869286023, 2949.631513704731, 2950.0184736440115, 2942.4214744281417, 2945.1534172611305, 2953.623491629044, 2938.719061792256, 2925.2368445069833, 2934.8454537565285, 2930.0742491243823, 2943.37727942149, 2958.942582298155, 2948.742498328232, 2932.6411218820394, 2943.4438459282164, 2938.9181387029384, 2938.8819408948366, 2925.7928114187853, 2934.711095137294, 2941.5186679989783, 2937.4849848576455, 2928.74556405887, 2949.264907119765, 2949.5160531809693, 2940.711045381097, 2942.7682348531926, 2949.378322625303, 2942.060688426893, 2943.581022770263, 2951.443604320754, 2938.2365630237728, 2940.682857091995, 2927.785265936271, 2901.2208159956767, 2940.964764303332, 2940.3647695749687, 2954.159822982919, 2942.901315784966, 2932.9855808004413, 2930.256162965783, 2937.509093694601, 2942.2561871768717, 2948.6291317165064, 2933.981361732941, 2934.9357015267246, 2941.3051385916556, 2912.0357122032515, 2939.5436972144275, 2945.222083779349, 2944.7132197718943, 2947.6537293765614, 2943.0424753813822, 2940.3828866359095, 2937.623616074635, 2941.6919316207236, 2948.309322906513, 2950.1846341949267, 2949.998211442646, 2938.7834069346236, 2926.2313573115803, 2939.0026037229472, 2937.0290005614247, 2940.398990877505, 2941.077542322394, 2942.7480721256256, 2939.0951186014317, 2926.54041177657, 2947.4494218631726, 2941.5750771698476, 2946.003896025505, 2929.8044185470653], [2100.7092557123096, 2945.620008696332, 2931.7363014516814, 2933.7368619500653, 2935.8605595744984, 2946.129186176204, 2944.6264073638845, 2929.7624493682715, 2941.6838723950145, 2928.841428794515, 2927.3861589129533, 2933.498413713168, 2956.0120691553793, 2942.6412142820927, 2929.694501818539, 2933.5705452248008, 2924.822497674425, 2940.5519899712376, 2942.58879629046, 2939.157468870014, 2941.3776545365017, 2933.0336512688627, 2945.49678187453, 2949.127200017578, 2939.6221622505836, 2938.02551963088, 2923.8866653414334, 2929.76045086594, 2949.8888003648412, 2941.5992531910942, 2934.259980829811, 2950.164369710957, 2945.1736129635256, 2940.2218539215464, 2928.9892325580604, 2925.438084112945, 2926.406812481646, 2937.342349002698, 2940.4996463842535, 2926.075857816838, 2937.408642817964, 2929.520650378999, 2937.923023778547, 2934.8875686919255, 2943.3631596404616, 2942.4476802100216, 2928.018794001572, 2929.8304000698527, 2926.574312045381, 2942.2521560124815, 2938.853787660552, 2945.117065694782, 2945.06052059741, 2924.7189293063834, 2938.0134609241236, 2936.6414248049973, 2938.0878245260715, 2937.975275672422, 2941.5327700888697, 2932.7953173247242, 2941.6012678774696, 2945.1695738008884, 2943.3853479286154, 2942.3247186616054, 2938.162191892526, 2929.924337112362, 2934.743179659581, 2926.6520862179873, 2927.4480133757106, 2946.875085164995, 2937.9973828024263, 2930.5860643601177, 2931.3421185540697, 2931.2400884770336, 2937.241909529525, 2949.1555504285407, 2947.851995426162, 2939.5597922649636, 2928.4180735566947, 2935.543514381539, 2932.975566317848, 2935.320821048632, 2934.0515126363284, 2936.6695356676446, 2932.957540421516, 2926.3689283344165, 2942.51622061572, 2943.08280918194, 2942.522268451879, 2949.734828151742, 2937.404624925795, 2922.8499848582287, 2928.6077694953347, 2928.1505442174553, 2945.882657638502, 2946.907436212176, 2932.899458484987, 2934.1657655737413, 2919.863445886598, 2928.9732530536226], []]=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f8c153c5048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-gpu
arch : resnet50
model_config : fanin
workers : 5
epochs : 2
start_epoch : 0
batch_size : 256
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.0
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 8
 ! Weight decay NOT applied to BN parameters 
98
63
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 311, in forward
    residual = self.downsample(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 2; 15.75 GiB total capacity; 11.87 GiB already allocated; 17.94 MiB free; 20.25 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 6; 15.75 GiB total capacity; 11.49 GiB already allocated; 359.94 MiB free; 20.25 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 311, in forward
    residual = self.downsample(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 7; 15.75 GiB total capacity; 11.87 GiB already allocated; 73.94 MiB free; 20.25 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 311, in forward
    residual = self.downsample(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 1; 15.75 GiB total capacity; 11.87 GiB already allocated; 57.94 MiB free; 20.25 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 15.75 GiB total capacity; 11.49 GiB already allocated; 183.94 MiB free; 20.25 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 5; 15.75 GiB total capacity; 11.49 GiB already allocated; 369.94 MiB free; 20.25 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 3; 15.75 GiB total capacity; 11.10 GiB already allocated; 317.94 MiB free; 20.25 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 4; 15.75 GiB total capacity; 11.49 GiB already allocated; 335.94 MiB free; 20.25 MiB cached)
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7ff8f0217048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-cpu
arch : resnet50
model_config : fanin
workers : 5
epochs : 2
start_epoch : 0
batch_size : 256
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.0
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 8
 ! Weight decay NOT applied to BN parameters 
98
63
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 15.75 GiB total capacity; 12.63 GiB already allocated; 277.94 MiB free; 20.24 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 2; 15.75 GiB total capacity; 13.02 GiB already allocated; 147.94 MiB free; 20.24 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 4; 15.75 GiB total capacity; 13.02 GiB already allocated; 91.94 MiB free; 20.24 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 6; 15.75 GiB total capacity; 13.02 GiB already allocated; 93.94 MiB free; 20.24 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 7; 15.75 GiB total capacity; 13.02 GiB already allocated; 189.94 MiB free; 20.24 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    main(args)
  File "main.py", line 282, in main
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 5; 15.75 GiB total capacity; 13.02 GiB already allocated; 109.94 MiB free; 20.24 MiB cached)
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 1; 15.75 GiB total capacity; 13.02 GiB already allocated; 169.94 MiB free; 20.24 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 3; 15.75 GiB total capacity; 12.63 GiB already allocated; 39.94 MiB free; 20.24 MiB cached)
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']

['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '8', 'main.py', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
CMD: "/opt/conda/bin/python multiproc.py --nproc_per_node 8 main.py -p 1 -j 5 --training-only  --workspace /data/workspace --epochs 2 --prof 100  -b 256 --data-backend dali-gpu --raport-file /data/workspace/./raport_8GPU_256BS_dali-gpu_trainingbench.json --no-checkpoints /data/imagenet --arch resnet50 -c fanin --label-smoothing 0.1 --mixup 0.0" exited with status 1
train.total_ips
[[126.48018415890625, 1673.3343265625438, 2948.432785174659, 2959.50123996811, 2950.334600029126, 2956.8423684659824, 2948.1797998380034, 2956.3070976001763, 2954.172014595578, 2941.0372634655337, 2946.7436663396293, 2952.8335702951617, 2954.6800879187404, 2947.4008777076665, 2953.593024103428, 2943.8433082059487, 2940.7573558863864, 2938.005421841278, 2953.8570968762465, 2957.5753729534385, 2946.4080960639253, 2949.238579767726, 2940.0185753088585, 2937.509093694601, 2941.8128253056734, 2947.28963671548, 2936.6012673633427, 2949.832071889912, 2946.590022269392, 2941.5488869286023, 2949.631513704731, 2950.0184736440115, 2942.4214744281417, 2945.1534172611305, 2953.623491629044, 2938.719061792256, 2925.2368445069833, 2934.8454537565285, 2930.0742491243823, 2943.37727942149, 2958.942582298155, 2948.742498328232, 2932.6411218820394, 2943.4438459282164, 2938.9181387029384, 2938.8819408948366, 2925.7928114187853, 2934.711095137294, 2941.5186679989783, 2937.4849848576455, 2928.74556405887, 2949.264907119765, 2949.5160531809693, 2940.711045381097, 2942.7682348531926, 2949.378322625303, 2942.060688426893, 2943.581022770263, 2951.443604320754, 2938.2365630237728, 2940.682857091995, 2927.785265936271, 2901.2208159956767, 2940.964764303332, 2940.3647695749687, 2954.159822982919, 2942.901315784966, 2932.9855808004413, 2930.256162965783, 2937.509093694601, 2942.2561871768717, 2948.6291317165064, 2933.981361732941, 2934.9357015267246, 2941.3051385916556, 2912.0357122032515, 2939.5436972144275, 2945.222083779349, 2944.7132197718943, 2947.6537293765614, 2943.0424753813822, 2940.3828866359095, 2937.623616074635, 2941.6919316207236, 2948.309322906513, 2950.1846341949267, 2949.998211442646, 2938.7834069346236, 2926.2313573115803, 2939.0026037229472, 2937.0290005614247, 2940.398990877505, 2941.077542322394, 2942.7480721256256, 2939.0951186014317, 2926.54041177657, 2947.4494218631726, 2941.5750771698476, 2946.003896025505, 2929.8044185470653], [2100.7092557123096, 2945.620008696332, 2931.7363014516814, 2933.7368619500653, 2935.8605595744984, 2946.129186176204, 2944.6264073638845, 2929.7624493682715, 2941.6838723950145, 2928.841428794515, 2927.3861589129533, 2933.498413713168, 2956.0120691553793, 2942.6412142820927, 2929.694501818539, 2933.5705452248008, 2924.822497674425, 2940.5519899712376, 2942.58879629046, 2939.157468870014, 2941.3776545365017, 2933.0336512688627, 2945.49678187453, 2949.127200017578, 2939.6221622505836, 2938.02551963088, 2923.8866653414334, 2929.76045086594, 2949.8888003648412, 2941.5992531910942, 2934.259980829811, 2950.164369710957, 2945.1736129635256, 2940.2218539215464, 2928.9892325580604, 2925.438084112945, 2926.406812481646, 2937.342349002698, 2940.4996463842535, 2926.075857816838, 2937.408642817964, 2929.520650378999, 2937.923023778547, 2934.8875686919255, 2943.3631596404616, 2942.4476802100216, 2928.018794001572, 2929.8304000698527, 2926.574312045381, 2942.2521560124815, 2938.853787660552, 2945.117065694782, 2945.06052059741, 2924.7189293063834, 2938.0134609241236, 2936.6414248049973, 2938.0878245260715, 2937.975275672422, 2941.5327700888697, 2932.7953173247242, 2941.6012678774696, 2945.1695738008884, 2943.3853479286154, 2942.3247186616054, 2938.162191892526, 2929.924337112362, 2934.743179659581, 2926.6520862179873, 2927.4480133757106, 2946.875085164995, 2937.9973828024263, 2930.5860643601177, 2931.3421185540697, 2931.2400884770336, 2937.241909529525, 2949.1555504285407, 2947.851995426162, 2939.5597922649636, 2928.4180735566947, 2935.543514381539, 2932.975566317848, 2935.320821048632, 2934.0515126363284, 2936.6695356676446, 2932.957540421516, 2926.3689283344165, 2942.51622061572, 2943.08280918194, 2942.522268451879, 2949.734828151742, 2937.404624925795, 2922.8499848582287, 2928.6077694953347, 2928.1505442174553, 2945.882657638502, 2946.907436212176, 2932.899458484987, 2934.1657655737413, 2919.863445886598, 2928.9732530536226], []]
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '8', 'main.py', '-p', '1', '-j', '5', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.0']
CMD: "/opt/conda/bin/python multiproc.py --nproc_per_node 8 main.py -p 1 -j 5 --training-only  --workspace /data/workspace --epochs 2 --prof 100  -b 256 --data-backend dali-cpu --raport-file /data/workspace/./raport_8GPU_256BS_dali-cpu_trainingbench.json --no-checkpoints /data/imagenet --arch resnet50 -c fanin --label-smoothing 0.1 --mixup 0.0" exited with status 1
train.total_ips
[[126.48018415890625, 1673.3343265625438, 2948.432785174659, 2959.50123996811, 2950.334600029126, 2956.8423684659824, 2948.1797998380034, 2956.3070976001763, 2954.172014595578, 2941.0372634655337, 2946.7436663396293, 2952.8335702951617, 2954.6800879187404, 2947.4008777076665, 2953.593024103428, 2943.8433082059487, 2940.7573558863864, 2938.005421841278, 2953.8570968762465, 2957.5753729534385, 2946.4080960639253, 2949.238579767726, 2940.0185753088585, 2937.509093694601, 2941.8128253056734, 2947.28963671548, 2936.6012673633427, 2949.832071889912, 2946.590022269392, 2941.5488869286023, 2949.631513704731, 2950.0184736440115, 2942.4214744281417, 2945.1534172611305, 2953.623491629044, 2938.719061792256, 2925.2368445069833, 2934.8454537565285, 2930.0742491243823, 2943.37727942149, 2958.942582298155, 2948.742498328232, 2932.6411218820394, 2943.4438459282164, 2938.9181387029384, 2938.8819408948366, 2925.7928114187853, 2934.711095137294, 2941.5186679989783, 2937.4849848576455, 2928.74556405887, 2949.264907119765, 2949.5160531809693, 2940.711045381097, 2942.7682348531926, 2949.378322625303, 2942.060688426893, 2943.581022770263, 2951.443604320754, 2938.2365630237728, 2940.682857091995, 2927.785265936271, 2901.2208159956767, 2940.964764303332, 2940.3647695749687, 2954.159822982919, 2942.901315784966, 2932.9855808004413, 2930.256162965783, 2937.509093694601, 2942.2561871768717, 2948.6291317165064, 2933.981361732941, 2934.9357015267246, 2941.3051385916556, 2912.0357122032515, 2939.5436972144275, 2945.222083779349, 2944.7132197718943, 2947.6537293765614, 2943.0424753813822, 2940.3828866359095, 2937.623616074635, 2941.6919316207236, 2948.309322906513, 2950.1846341949267, 2949.998211442646, 2938.7834069346236, 2926.2313573115803, 2939.0026037229472, 2937.0290005614247, 2940.398990877505, 2941.077542322394, 2942.7480721256256, 2939.0951186014317, 2926.54041177657, 2947.4494218631726, 2941.5750771698476, 2946.003896025505, 2929.8044185470653], [2100.7092557123096, 2945.620008696332, 2931.7363014516814, 2933.7368619500653, 2935.8605595744984, 2946.129186176204, 2944.6264073638845, 2929.7624493682715, 2941.6838723950145, 2928.841428794515, 2927.3861589129533, 2933.498413713168, 2956.0120691553793, 2942.6412142820927, 2929.694501818539, 2933.5705452248008, 2924.822497674425, 2940.5519899712376, 2942.58879629046, 2939.157468870014, 2941.3776545365017, 2933.0336512688627, 2945.49678187453, 2949.127200017578, 2939.6221622505836, 2938.02551963088, 2923.8866653414334, 2929.76045086594, 2949.8888003648412, 2941.5992531910942, 2934.259980829811, 2950.164369710957, 2945.1736129635256, 2940.2218539215464, 2928.9892325580604, 2925.438084112945, 2926.406812481646, 2937.342349002698, 2940.4996463842535, 2926.075857816838, 2937.408642817964, 2929.520650378999, 2937.923023778547, 2934.8875686919255, 2943.3631596404616, 2942.4476802100216, 2928.018794001572, 2929.8304000698527, 2926.574312045381, 2942.2521560124815, 2938.853787660552, 2945.117065694782, 2945.06052059741, 2924.7189293063834, 2938.0134609241236, 2936.6414248049973, 2938.0878245260715, 2937.975275672422, 2941.5327700888697, 2932.7953173247242, 2941.6012678774696, 2945.1695738008884, 2943.3853479286154, 2942.3247186616054, 2938.162191892526, 2929.924337112362, 2934.743179659581, 2926.6520862179873, 2927.4480133757106, 2946.875085164995, 2937.9973828024263, 2930.5860643601177, 2931.3421185540697, 2931.2400884770336, 2937.241909529525, 2949.1555504285407, 2947.851995426162, 2939.5597922649636, 2928.4180735566947, 2935.543514381539, 2932.975566317848, 2935.320821048632, 2934.0515126363284, 2936.6695356676446, 2932.957540421516, 2926.3689283344165, 2942.51622061572, 2943.08280918194, 2942.522268451879, 2949.734828151742, 2937.404624925795, 2922.8499848582287, 2928.6077694953347, 2928.1505442174553, 2945.882657638502, 2946.907436212176, 2932.899458484987, 2934.1657655737413, 2919.863445886598, 2928.9732530536226], []]
 train.total_ips |       8 p |       8 d-g |       8 d-c |
----------------------------------------------------------
             128 |    2920.3 |    2902.3 |    2936.7 |
             256 |      -1.0 |      -1.0 |      -1.0 |
