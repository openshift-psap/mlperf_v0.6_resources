resnet50v1.5: Pulling from asulecki/pytorch-off/conv_tests
Digest: sha256:205281eea3cedb2a9ac3d3738680d0d1f51c36b89aed411e2e24fba82bc54293
Status: Image is up to date for gitlab-master.nvidia.com:5005/asulecki/pytorch-off/conv_tests:resnet50v1.5

=============
== PyTorch ==
=============

NVIDIA Release 19.04 (build 6012988)
PyTorch Version 1.1.0a0+9eb0f43

Container image Copyright (c) 2019, NVIDIA CORPORATION.  All rights reserved.

Copyright (c) 2014-2019 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.
NVIDIA modifications are covered by the license terms that apply to the underlying project or file.

Detected MOFED 4.4-1.0.0.

=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f49ab702048>}
data : /data/imagenet
data_backend : pytorch
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 224
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Epoch: 0/2  Iteration: 1/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.082
Epoch: 0/2  Iteration: 2/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.019
Epoch: 0/2  Iteration: 3/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.979
Epoch: 0/2  Iteration: 4/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.966
Epoch: 0/2  Iteration: 5/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.985
Epoch: 0/2  Iteration: 6/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.003
Epoch: 0/2  Iteration: 7/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.011
Epoch: 0/2  Iteration: 8/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.018
Epoch: 0/2  Iteration: 9/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.028
Epoch: 0/2  Iteration: 10/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.996
Epoch: 0/2  Iteration: 11/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.984
Epoch: 0/2  Iteration: 12/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.988
Epoch: 0/2  Iteration: 13/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.982
Epoch: 0/2  Iteration: 14/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.993
Epoch: 0/2  Iteration: 15/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.987
Epoch: 0/2  Iteration: 16/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.998
Epoch: 0/2  Iteration: 17/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.990
Epoch: 0/2  Iteration: 18/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.986
Epoch: 0/2  Iteration: 19/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.013
Epoch: 0/2  Iteration: 20/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.010
Epoch: 0/2  Iteration: 21/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.017
Epoch: 0/2  Iteration: 22/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.015
Epoch: 0/2  Iteration: 23/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.995
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
Epoch: 0/2  Iteration: 24/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.974
Epoch: 0/2  Iteration: 25/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.986
Epoch: 0/2  Iteration: 26/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.001
Epoch: 0/2  Iteration: 27/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.969
Epoch: 0/2  Iteration: 28/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.974
Epoch: 0/2  Iteration: 29/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.978
Epoch: 0/2  Iteration: 30/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.949
Epoch: 0/2  Iteration: 31/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.948
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
Epoch: 0/2  Iteration: 32/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.959
Epoch: 0/2  Iteration: 33/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.940
Epoch: 0/2  Iteration: 34/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.936
Epoch: 0/2  Iteration: 35/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.946
Epoch: 0/2  Iteration: 36/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.927
Epoch: 0/2  Iteration: 37/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.926
Epoch: 0/2  Iteration: 38/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.918
Epoch: 0/2  Iteration: 39/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.905
Epoch: 0/2  Iteration: 40/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 0/2  Iteration: 41/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 0/2  Iteration: 42/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.892
Epoch: 0/2  Iteration: 43/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.906
Epoch: 0/2  Iteration: 44/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 0/2  Iteration: 45/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.897
Epoch: 0/2  Iteration: 46/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 0/2  Iteration: 47/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.900
Epoch: 0/2  Iteration: 48/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.875
Epoch: 0/2  Iteration: 49/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.873
Epoch: 0/2  Iteration: 50/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.883
Epoch: 0/2  Iteration: 51/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.850
Epoch: 0/2  Iteration: 52/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.851
Epoch: 0/2  Iteration: 53/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.877
Epoch: 0/2  Iteration: 54/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.865
Epoch: 0/2  Iteration: 55/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.827
Epoch: 0/2  Iteration: 56/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.839
Epoch: 0/2  Iteration: 57/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.840
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
Epoch: 0/2  Iteration: 58/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.853
Epoch: 0/2  Iteration: 59/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.844
Epoch: 0/2  Iteration: 60/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.830
Epoch: 0/2  Iteration: 61/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.840
Epoch: 0/2  Iteration: 62/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.840
Epoch: 0/2  Iteration: 63/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.820
Epoch: 0/2  Iteration: 64/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.822
Epoch: 0/2  Iteration: 65/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.812
Epoch: 0/2  Iteration: 66/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.808
Epoch: 0/2  Iteration: 67/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.815
Epoch: 0/2  Iteration: 68/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.815
Epoch: 0/2  Iteration: 69/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.791
Epoch: 0/2  Iteration: 70/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.772
Epoch: 0/2  Iteration: 71/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.796
Epoch: 0/2  Iteration: 72/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.815
Epoch: 0/2  Iteration: 73/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.800
Epoch: 0/2  Iteration: 74/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.776
Epoch: 0/2  Iteration: 75/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.760
Epoch: 0/2  Iteration: 76/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.750
Epoch: 0/2  Iteration: 77/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.746
Epoch: 0/2  Iteration: 78/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.761
Epoch: 0/2  Iteration: 79/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.753
Epoch: 0/2  Iteration: 80/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.736
Epoch: 0/2  Iteration: 81/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.728
Epoch: 0/2  Iteration: 82/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.729
Epoch: 0/2  Iteration: 83/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.726
Epoch: 0/2  Iteration: 84/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.717
Epoch: 0/2  Iteration: 85/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.712
Epoch: 0/2  Iteration: 86/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.689
Epoch: 0/2  Iteration: 87/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.697
Epoch: 0/2  Iteration: 88/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.719
Epoch: 0/2  Iteration: 89/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.735
Epoch: 0/2  Iteration: 90/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.702
Epoch: 0/2  Iteration: 91/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.686
Epoch: 0/2  Iteration: 92/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.697
Epoch: 0/2  Iteration: 93/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.661
Epoch: 0/2  Iteration: 94/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.677
Epoch: 0/2  Iteration: 95/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.684
Epoch: 0/2  Iteration: 96/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.656
Epoch: 0/2  Iteration: 97/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.635
Epoch: 0/2  Iteration: 98/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.664
Epoch: 0/2  Iteration: 99/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.652
Epoch: 0/2  Iteration: 100/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.641
Summary Epoch: 0/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.862
Epoch: 1/2  Iteration: 1/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.631
Epoch: 1/2  Iteration: 2/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.621
Epoch: 1/2  Iteration: 3/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.623
Epoch: 1/2  Iteration: 4/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.598
Epoch: 1/2  Iteration: 5/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.625
Epoch: 1/2  Iteration: 6/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.594
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19660800 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18481152 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 37093376 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 39976960 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 34865152 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. 
  warnings.warn(str(msg))
Epoch: 1/2  Iteration: 7/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.595
Epoch: 1/2  Iteration: 8/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.610
Epoch: 1/2  Iteration: 9/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.601
Epoch: 1/2  Iteration: 10/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.613
Epoch: 1/2  Iteration: 11/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.635
Epoch: 1/2  Iteration: 12/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.558
Epoch: 1/2  Iteration: 13/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.565
Epoch: 1/2  Iteration: 14/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.571
Epoch: 1/2  Iteration: 15/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.571
Epoch: 1/2  Iteration: 16/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.552
Epoch: 1/2  Iteration: 17/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.608
Epoch: 1/2  Iteration: 18/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.562
Epoch: 1/2  Iteration: 19/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.542
Epoch: 1/2  Iteration: 20/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.563
Epoch: 1/2  Iteration: 21/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.529
Epoch: 1/2  Iteration: 22/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.573
Epoch: 1/2  Iteration: 23/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.531
Epoch: 1/2  Iteration: 24/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.526
Epoch: 1/2  Iteration: 25/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.531
Epoch: 1/2  Iteration: 26/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.509
Epoch: 1/2  Iteration: 27/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.515
Epoch: 1/2  Iteration: 28/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.517
Epoch: 1/2  Iteration: 29/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.506
Epoch: 1/2  Iteration: 30/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.534
Epoch: 1/2  Iteration: 31/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.479
Epoch: 1/2  Iteration: 32/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.470
Epoch: 1/2  Iteration: 33/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.481
Epoch: 1/2  Iteration: 34/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.480
Epoch: 1/2  Iteration: 35/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.495
Epoch: 1/2  Iteration: 36/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.503
Epoch: 1/2  Iteration: 37/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.500
Epoch: 1/2  Iteration: 38/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.493
Epoch: 1/2  Iteration: 39/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.485
Epoch: 1/2  Iteration: 40/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.426
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1835008 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
Epoch: 1/2  Iteration: 41/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.497
Epoch: 1/2  Iteration: 42/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.474
Epoch: 1/2  Iteration: 43/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.404
Epoch: 1/2  Iteration: 44/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.473
Epoch: 1/2  Iteration: 45/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.426
Epoch: 1/2  Iteration: 46/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.467
Epoch: 1/2  Iteration: 47/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.451
Epoch: 1/2  Iteration: 48/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.423
Epoch: 1/2  Iteration: 49/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.437
Epoch: 1/2  Iteration: 50/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.398
Epoch: 1/2  Iteration: 51/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.467
Epoch: 1/2  Iteration: 52/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.387
Epoch: 1/2  Iteration: 53/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.413
Epoch: 1/2  Iteration: 54/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.445
Epoch: 1/2  Iteration: 55/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.416
Epoch: 1/2  Iteration: 56/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.395
Epoch: 1/2  Iteration: 57/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.383
Epoch: 1/2  Iteration: 58/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.376
Epoch: 1/2  Iteration: 59/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.434
Epoch: 1/2  Iteration: 60/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.375
Epoch: 1/2  Iteration: 61/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.369
Epoch: 1/2  Iteration: 62/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.419
Epoch: 1/2  Iteration: 63/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.398
Epoch: 1/2  Iteration: 64/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.403
Epoch: 1/2  Iteration: 65/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.394
Epoch: 1/2  Iteration: 66/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.381
Epoch: 1/2  Iteration: 67/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.380
Epoch: 1/2  Iteration: 68/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.341
Epoch: 1/2  Iteration: 69/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.330
Epoch: 1/2  Iteration: 70/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.404
Epoch: 1/2  Iteration: 71/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.349
Epoch: 1/2  Iteration: 72/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.323
Epoch: 1/2  Iteration: 73/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.324
Epoch: 1/2  Iteration: 74/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.343
Epoch: 1/2  Iteration: 75/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.382
Epoch: 1/2  Iteration: 76/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.321
Epoch: 1/2  Iteration: 77/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.399
Epoch: 1/2  Iteration: 78/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.288
Epoch: 1/2  Iteration: 79/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.365
Epoch: 1/2  Iteration: 80/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.392
Epoch: 1/2  Iteration: 81/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.293
Epoch: 1/2  Iteration: 82/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.277
Epoch: 1/2  Iteration: 83/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.276
Epoch: 1/2  Iteration: 84/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.335
Epoch: 1/2  Iteration: 85/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.385
Epoch: 1/2  Iteration: 86/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.392
Epoch: 1/2  Iteration: 87/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.274
Epoch: 1/2  Iteration: 88/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.275
Epoch: 1/2  Iteration: 89/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.286
Epoch: 1/2  Iteration: 90/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.230
Epoch: 1/2  Iteration: 91/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.282
Epoch: 1/2  Iteration: 92/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.268
Epoch: 1/2  Iteration: 93/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.279
Epoch: 1/2  Iteration: 94/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.256
Epoch: 1/2  Iteration: 95/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.259
Epoch: 1/2  Iteration: 96/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.273
Epoch: 1/2  Iteration: 97/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.254
Epoch: 1/2  Iteration: 98/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.211
Epoch: 1/2  Iteration: 99/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.288
Epoch: 1/2  Iteration: 100/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.260
Summary Epoch: 1/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.434
None
Experiment ended
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7faf2a840048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-gpu
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 224
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Epoch: 0/2  Iteration: 1/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.081
Epoch: 0/2  Iteration: 2/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.028
Epoch: 0/2  Iteration: 3/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.986
Epoch: 0/2  Iteration: 4/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.978
Epoch: 0/2  Iteration: 5/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.990
Epoch: 0/2  Iteration: 6/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.007
Epoch: 0/2  Iteration: 7/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.044
Epoch: 0/2  Iteration: 8/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.031
Epoch: 0/2  Iteration: 9/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.035
Epoch: 0/2  Iteration: 10/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.057
Epoch: 0/2  Iteration: 11/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.044
Epoch: 0/2  Iteration: 12/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.046
Epoch: 0/2  Iteration: 13/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.061
Epoch: 0/2  Iteration: 14/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.090
Epoch: 0/2  Iteration: 15/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.060
Epoch: 0/2  Iteration: 16/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.027
Epoch: 0/2  Iteration: 17/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.096
Epoch: 0/2  Iteration: 18/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.082
Epoch: 0/2  Iteration: 19/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.090
Epoch: 0/2  Iteration: 20/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.126
Epoch: 0/2  Iteration: 21/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.071
Epoch: 0/2  Iteration: 22/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.070
Epoch: 0/2  Iteration: 23/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.124
Epoch: 0/2  Iteration: 24/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.071
Epoch: 0/2  Iteration: 25/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.055
Epoch: 0/2  Iteration: 26/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.090
Epoch: 0/2  Iteration: 27/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.083
Epoch: 0/2  Iteration: 28/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.053
Epoch: 0/2  Iteration: 29/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.042
Epoch: 0/2  Iteration: 30/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.016
Epoch: 0/2  Iteration: 31/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.072
Epoch: 0/2  Iteration: 32/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.029
Epoch: 0/2  Iteration: 33/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.014
Epoch: 0/2  Iteration: 34/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.043
Epoch: 0/2  Iteration: 35/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.982
Epoch: 0/2  Iteration: 36/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.024
Epoch: 0/2  Iteration: 37/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.969
Epoch: 0/2  Iteration: 38/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.009
Epoch: 0/2  Iteration: 39/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.017
Epoch: 0/2  Iteration: 40/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.997
Epoch: 0/2  Iteration: 41/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.987
Epoch: 0/2  Iteration: 42/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.985
Epoch: 0/2  Iteration: 43/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.964
Epoch: 0/2  Iteration: 44/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.007
Epoch: 0/2  Iteration: 45/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.970
Epoch: 0/2  Iteration: 46/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.983
Epoch: 0/2  Iteration: 47/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.953
Epoch: 0/2  Iteration: 48/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.982
Epoch: 0/2  Iteration: 49/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.965
Epoch: 0/2  Iteration: 50/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.981
Epoch: 0/2  Iteration: 51/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.940
Epoch: 0/2  Iteration: 52/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.928
Epoch: 0/2  Iteration: 53/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.939
Epoch: 0/2  Iteration: 54/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.957
Epoch: 0/2  Iteration: 55/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.918
Epoch: 0/2  Iteration: 56/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.934
Epoch: 0/2  Iteration: 57/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.943
Epoch: 0/2  Iteration: 58/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.929
Epoch: 0/2  Iteration: 59/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.916
Epoch: 0/2  Iteration: 60/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 0/2  Iteration: 61/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 0/2  Iteration: 62/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 0/2  Iteration: 63/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.899
Epoch: 0/2  Iteration: 64/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.891
Epoch: 0/2  Iteration: 65/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.892
Epoch: 0/2  Iteration: 66/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.892
Epoch: 0/2  Iteration: 67/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.875
Epoch: 0/2  Iteration: 68/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.884
Epoch: 0/2  Iteration: 69/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.878
Epoch: 0/2  Iteration: 70/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.873
Epoch: 0/2  Iteration: 71/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.863
Epoch: 0/2  Iteration: 72/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.867
Epoch: 0/2  Iteration: 73/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.863
Epoch: 0/2  Iteration: 74/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.868
Epoch: 0/2  Iteration: 75/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.846
Epoch: 0/2  Iteration: 76/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.841
Epoch: 0/2  Iteration: 77/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.838
Epoch: 0/2  Iteration: 78/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.851
Epoch: 0/2  Iteration: 79/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.830
Epoch: 0/2  Iteration: 80/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.824
Epoch: 0/2  Iteration: 81/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.817
Epoch: 0/2  Iteration: 82/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.801
Epoch: 0/2  Iteration: 83/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.815
Epoch: 0/2  Iteration: 84/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.803
Epoch: 0/2  Iteration: 85/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.807
Epoch: 0/2  Iteration: 86/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.794
Epoch: 0/2  Iteration: 87/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.785
Epoch: 0/2  Iteration: 88/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.784
Epoch: 0/2  Iteration: 89/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.772
Epoch: 0/2  Iteration: 90/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.765
Epoch: 0/2  Iteration: 91/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.753
Epoch: 0/2  Iteration: 92/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.757
Epoch: 0/2  Iteration: 93/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.760
Epoch: 0/2  Iteration: 94/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.742
Epoch: 0/2  Iteration: 95/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.739
Epoch: 0/2  Iteration: 96/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.744
Epoch: 0/2  Iteration: 97/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.723
Epoch: 0/2  Iteration: 98/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.740
Epoch: 0/2  Iteration: 99/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.747
Epoch: 0/2  Iteration: 100/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.713
Summary Epoch: 0/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.936
Epoch: 1/2  Iteration: 1/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.709
Epoch: 1/2  Iteration: 2/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.671
Epoch: 1/2  Iteration: 3/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.686
Epoch: 1/2  Iteration: 4/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.703
Epoch: 1/2  Iteration: 5/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.716
Epoch: 1/2  Iteration: 6/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.692
Epoch: 1/2  Iteration: 7/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.717
Epoch: 1/2  Iteration: 8/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.674
Epoch: 1/2  Iteration: 9/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.698
Epoch: 1/2  Iteration: 10/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.693
Epoch: 1/2  Iteration: 11/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.640
Epoch: 1/2  Iteration: 12/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.664
Epoch: 1/2  Iteration: 13/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.632
Epoch: 1/2  Iteration: 14/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.685
Epoch: 1/2  Iteration: 15/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.655
Epoch: 1/2  Iteration: 16/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.634
Epoch: 1/2  Iteration: 17/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.671
Epoch: 1/2  Iteration: 18/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.639
Epoch: 1/2  Iteration: 19/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.640
Epoch: 1/2  Iteration: 20/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.623
Epoch: 1/2  Iteration: 21/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.627
Epoch: 1/2  Iteration: 22/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.601
Epoch: 1/2  Iteration: 23/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.616
Epoch: 1/2  Iteration: 24/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.640
Epoch: 1/2  Iteration: 25/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.590
Epoch: 1/2  Iteration: 26/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.600
Epoch: 1/2  Iteration: 27/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.582
Epoch: 1/2  Iteration: 28/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.581
Epoch: 1/2  Iteration: 29/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.596
Epoch: 1/2  Iteration: 30/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.555
Epoch: 1/2  Iteration: 31/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.534
Epoch: 1/2  Iteration: 32/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.562
Epoch: 1/2  Iteration: 33/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.526
Epoch: 1/2  Iteration: 34/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.552
Epoch: 1/2  Iteration: 35/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.566
Epoch: 1/2  Iteration: 36/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.537
Epoch: 1/2  Iteration: 37/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.613
Epoch: 1/2  Iteration: 38/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.521
Epoch: 1/2  Iteration: 39/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.554
Epoch: 1/2  Iteration: 40/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.533
Epoch: 1/2  Iteration: 41/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.576
Epoch: 1/2  Iteration: 42/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.546
Epoch: 1/2  Iteration: 43/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.512
Epoch: 1/2  Iteration: 44/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.526
Epoch: 1/2  Iteration: 45/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.540
Epoch: 1/2  Iteration: 46/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.475
Epoch: 1/2  Iteration: 47/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.524
Epoch: 1/2  Iteration: 48/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.499
Epoch: 1/2  Iteration: 49/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.501
Epoch: 1/2  Iteration: 50/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.477
Epoch: 1/2  Iteration: 51/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.502
Epoch: 1/2  Iteration: 52/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.485
Epoch: 1/2  Iteration: 53/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.460
Epoch: 1/2  Iteration: 54/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.485
Epoch: 1/2  Iteration: 55/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.476
Epoch: 1/2  Iteration: 56/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.426
Epoch: 1/2  Iteration: 57/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.491
Epoch: 1/2  Iteration: 58/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.447
Epoch: 1/2  Iteration: 59/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.482
Epoch: 1/2  Iteration: 60/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.414
Epoch: 1/2  Iteration: 61/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.469
Epoch: 1/2  Iteration: 62/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.416
Epoch: 1/2  Iteration: 63/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.431
Epoch: 1/2  Iteration: 64/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.430
Epoch: 1/2  Iteration: 65/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.384
Epoch: 1/2  Iteration: 66/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.423
Epoch: 1/2  Iteration: 67/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.418
Epoch: 1/2  Iteration: 68/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.423
Epoch: 1/2  Iteration: 69/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.436
Epoch: 1/2  Iteration: 70/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.409
Epoch: 1/2  Iteration: 71/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.429
Epoch: 1/2  Iteration: 72/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.471
Epoch: 1/2  Iteration: 73/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.387
Epoch: 1/2  Iteration: 74/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.423
Epoch: 1/2  Iteration: 75/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.407
Epoch: 1/2  Iteration: 76/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.341
Epoch: 1/2  Iteration: 77/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.404
Epoch: 1/2  Iteration: 78/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.416
Epoch: 1/2  Iteration: 79/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.392
Epoch: 1/2  Iteration: 80/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.381
Epoch: 1/2  Iteration: 81/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.388
Epoch: 1/2  Iteration: 82/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.384
Epoch: 1/2  Iteration: 83/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.394
Epoch: 1/2  Iteration: 84/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.348
Epoch: 1/2  Iteration: 85/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.367
Epoch: 1/2  Iteration: 86/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.349
Epoch: 1/2  Iteration: 87/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.334
Epoch: 1/2  Iteration: 88/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.368
Epoch: 1/2  Iteration: 89/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.294
Epoch: 1/2  Iteration: 90/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.310
Epoch: 1/2  Iteration: 91/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.290
Epoch: 1/2  Iteration: 92/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.329
Epoch: 1/2  Iteration: 93/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.338
Epoch: 1/2  Iteration: 94/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.320
Epoch: 1/2  Iteration: 95/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.332
Epoch: 1/2  Iteration: 96/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.325
Epoch: 1/2  Iteration: 97/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.383
Epoch: 1/2  Iteration: 98/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.282
Epoch: 1/2  Iteration: 99/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.324
Epoch: 1/2  Iteration: 100/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.278
Summary Epoch: 1/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.498
None
Experiment ended
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_224BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
Job ended sucessfully
train.total_ips
[[152.06899765641504, 1857.0963841906741, 6246.503483857242, 6192.2113009077175, 6203.628953927929, 6190.140804796495, 6161.783467562108, 6202.019043736893, 6178.401932715015, 6228.8511793574735, 6201.041731792023, 6217.898640758868, 6198.047754089938, 6200.565979350401, 6197.508582991178, 5661.380237122592, 6191.953688405913, 6209.599821548808, 6216.371288809454, 6170.433551323456, 6229.117033703582, 6197.569905781378, 6177.5564412894455, 6227.431952799994, 6173.613872368981, 6204.304904543984, 6225.933435743281, 6153.449779771749, 6182.579464590505, 6131.4281211276775, 6171.616602668031, 6166.0270696084435, 6161.326346413247, 6211.087919016631, 6203.457429287475, 6171.2669599777, 6189.70750182203, 6153.525347436847, 6155.092535299156, 6187.6310386202495, 6199.63770497212, 6188.410504384511, 5760.229888281536, 6212.081236003856, 6180.101232329586, 6185.237828885784, 6152.71183314758, 6199.647932376411, 6206.487386686616, 6193.361891613178, 6165.741283402719, 5669.072793975671, 6189.699855843644, 6160.371914309425, 6182.0709472324925, 6170.995887476632, 6196.1419107633355, 6179.0977959371585, 6201.284751798211, 6181.0262065993675, 5889.399328017652, 6192.509750110298, 6166.095358729403, 6139.574339753337, 6222.822641684391, 6182.826125636641, 6178.996200294308, 6193.165419029076, 6185.4159828333595, 5892.624465759407, 6200.565979350401, 6183.082979188981, 6175.150723298149, 6228.89763770392, 6148.740541011482, 6198.850296161529, 6123.430701748669, 6209.940994680458, 5645.404508471457, 6185.90723187751, 6167.147708261025, 6216.756912925039, 6187.490959382255, 6097.336473321592, 6188.805406749544, 6163.268948121957, 6208.5021654032735, 5605.927966120657, 6166.682201668966, 6181.737913700514, 6140.35177692697, 6182.734579034108, 6192.162837513032, 6209.245861985784, 6154.01658250416, 6187.638679488372, 5927.211177506196, 6185.993781243982, 6176.668036028544, 6200.944529122696], [1799.3330161360075, 5540.247040326451, 6140.384383432498, 6083.673265912271, 6119.140890093979, 6115.844739967314, 6135.862911553919, 6174.904674273095, 6169.240826095646, 6171.044020107104, 6137.9849682022805, 6154.555771774683, 6173.26907362683, 6145.711414082443, 6121.742475585128, 6205.444624473313, 6169.473763787283, 6192.262315826937, 6181.928577362187, 6198.725045019189, 6180.695826862723, 6131.9908740432775, 6170.370231600499, 6185.869049103397, 6125.923596630177, 6168.5927442106295, 6107.523102113119, 6132.165973797003, 6179.819221079912, 6167.939736933778, 6183.99867042502, 6175.650491467616, 6206.610389117075, 6202.152104786946, 6153.207975715263, 6187.766030068677, 6197.449816455967, 6158.239398284324, 6161.4172601332675, 6169.597835606925, 6167.752465786305, 6162.212869643354, 6141.1193757723695, 6173.256397936497, 6149.558036806403, 6180.733945799084, 5803.602038775653, 6171.862389720614, 6185.303999154027, 6157.248091986075, 6165.387248737793, 6192.18579376332, 6172.463003332108, 6216.484400258214, 6131.288074232691, 6209.469005704948, 6160.62943034901, 6162.710545745842, 6145.236576955545, 6145.060729972959, 6179.059697179581, 6202.730474918414, 6192.0557105955495, 6213.609048687455, 6180.3299089954135, 6137.243208970793, 6185.314179320958, 6180.642461141729, 6200.486694374003, 6175.214141173474, 6131.120526531956, 6146.882490094172, 6170.851494090182, 6125.324517742897, 6139.416368525434, 6182.429443270714, 6184.476972547419, 6173.195555347488, 6189.699855843644, 6115.949246083749, 6153.278499935325, 6194.311259454303, 5809.336954156804, 6192.866906624492, 6138.185474449723, 6202.945471846274, 6148.169680550409, 6150.56196740924, 6098.699489746034, 6195.628606485047, 6174.372057986348, 6150.778396395062, 6152.978783164225, 6158.796990657567, 6126.977261231518, 6152.142752898681, 6131.4131157972015, 6178.297820676957, 6136.904966144194, 6185.161480335501], []]
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
Job ended sucessfully
train.total_ips
[[194.32720205712664, 2351.5597277254014, 6115.98905887709, 6109.218390421551, 5905.630018939803, 6135.675078785811, 6148.966902700985, 5823.598736754674, 6123.650214599268, 6113.606181123546, 6100.162132242539, 6147.764861386426, 6100.248774361107, 6130.427926498739, 6138.085219688571, 6134.971434261745, 5855.064210864153, 6129.605510957938, 6119.464721775446, 6052.532937786776, 6062.032428944736, 6077.359640930727, 6052.608484144723, 6138.779551103049, 6137.889732323499, 5864.214283317924, 6126.050915990653, 6109.747274623495, 6115.210315206761, 6149.85238850917, 6159.130080424737, 6140.803282418643, 6142.303760838751, 6162.581698028122, 6129.608010366895, 6151.742445361308, 6129.5730188269945, 6154.109800062063, 6103.329881960112, 6144.746742533866, 6129.630505139224, 6147.214292315607, 6135.712644419428, 5839.284549055802, 5946.623200571545, 6128.673373570407, 6096.275671771504, 6144.688972340207, 6138.142865776076, 6139.213274605538, 6126.82243471364, 6168.868668679677, 6104.918709845107, 6116.3598404058375, 6133.249313127967, 6161.083922942523, 6158.375633253392, 6148.26272106, 6170.496872345989, 6127.676575241675, 6114.240273067528, 6128.735840402549, 6162.3417019383905, 6155.147980997819, 6145.741564948912, 6149.93793189503, 6136.353835490173, 6112.199215501948, 6135.459711364881, 6136.769679452636, 5817.198504098868, 6054.239282918075, 6106.297520822298, 6073.838370223117, 6125.574119705611, 6133.677250035193, 6132.313565641649, 6130.007942055131, 6046.860168738149, 5861.50465707061, 6137.1454905467035, 6169.438315612522, 6135.544854817189, 6126.005979141469, 6103.2059831971255, 6151.843146755674, 6114.242759961523, 6125.808764099248, 5844.83115317754, 6138.04511870108, 6141.744132153608, 6120.488753605345, 6073.556157741949, 6105.007966522411, 6139.338639635537, 6141.202167504429, 6119.631633026926, 5879.25294727542, 6137.52385354101, 6164.024594778673], [5055.839336596181, 6107.7588472266525, 6122.954313228004, 6115.785023790005, 6156.161301049535, 6125.823742011306, 6112.49994347953, 6137.739365900245, 6118.702526423675, 6097.751992711443, 6117.420175248687, 6111.528276273673, 6147.395290443892, 6147.432999728869, 6136.53669968767, 6121.565477732114, 6142.409173170063, 6130.250426052081, 6145.455143661456, 6137.097885262238, 6137.303344932343, 6102.366082236936, 6109.846605813635, 6125.389412296347, 5779.128368941288, 6100.941999922888, 6111.538215039153, 6085.276508650004, 6140.803282418643, 6141.52833847157, 6132.856464567466, 6117.094070697177, 6157.058947658149, 5834.615685212081, 6139.255898141281, 6111.09348692523, 6142.491999682913, 6146.9553829665165, 6045.867919352958, 6098.080985728374, 6104.274155770324, 6118.934153946351, 5698.395921460286, 6110.425274203993, 6139.927923865539, 6123.4531512041085, 6132.343585191374, 6122.246102931084, 6140.161161208999, 6128.700858819669, 6148.353249664103, 6136.66947093403, 6127.129598184408, 6121.518113845425, 6161.697594327055, 6121.353592354857, 6140.893591484998, 6135.995653645154, 6136.930019889806, 6111.801604103486, 6139.092928993443, 5813.781052092571, 6150.491505444756, 6124.653189407131, 6147.1237972482595, 6131.958356618567, 6150.858931998991, 6105.245997088792, 6098.016668512413, 6121.899538588725, 6135.890461326962, 6122.872012773307, 6145.045657842724, 6151.933780829475, 6141.947393559537, 6144.889916826191, 6118.042608680788, 6139.787488420801, 6134.893817881744, 6120.8351582308505, 6112.671446236749, 6129.290601737213, 6086.43698541228, 6145.967705877687, 6110.939462111277, 6073.698487715339, 6128.680869523029, 6123.794902128527, 5961.9438230499845, 6106.163580219332, 6067.466762783552, 6117.584485370184, 6131.358096880478, 6086.170849722158, 6123.325939799702, 6132.195991901727, 6096.347369334602, 6128.033786483124, 6113.690719117035, 6130.395425648228], []]=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f73fa4eb048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-cpu
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 224
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Epoch: 0/2  Iteration: 1/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.096
Epoch: 0/2  Iteration: 2/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.026
Epoch: 0/2  Iteration: 3/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.971
Epoch: 0/2  Iteration: 4/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.983
Epoch: 0/2  Iteration: 5/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.981
Epoch: 0/2  Iteration: 6/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.000
Epoch: 0/2  Iteration: 7/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.023
Epoch: 0/2  Iteration: 8/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.024
Epoch: 0/2  Iteration: 9/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.030
Epoch: 0/2  Iteration: 10/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.007
Epoch: 0/2  Iteration: 11/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.007
Epoch: 0/2  Iteration: 12/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.013
Epoch: 0/2  Iteration: 13/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.989
Epoch: 0/2  Iteration: 14/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.036
Epoch: 0/2  Iteration: 15/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.992
Epoch: 0/2  Iteration: 16/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.013
Epoch: 0/2  Iteration: 17/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.018
Epoch: 0/2  Iteration: 18/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.008
Epoch: 0/2  Iteration: 19/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.025
Epoch: 0/2  Iteration: 20/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.007
Epoch: 0/2  Iteration: 21/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.007
Epoch: 0/2  Iteration: 22/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.998
Epoch: 0/2  Iteration: 23/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.017
Epoch: 0/2  Iteration: 24/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.002
Epoch: 0/2  Iteration: 25/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.974
Epoch: 0/2  Iteration: 26/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.993
Epoch: 0/2  Iteration: 27/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.977
Epoch: 0/2  Iteration: 28/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.989
Epoch: 0/2  Iteration: 29/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.969
Epoch: 0/2  Iteration: 30/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.972
Epoch: 0/2  Iteration: 31/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.951
Epoch: 0/2  Iteration: 32/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.933
Epoch: 0/2  Iteration: 33/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.952
Epoch: 0/2  Iteration: 34/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.935
Epoch: 0/2  Iteration: 35/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.945
Epoch: 0/2  Iteration: 36/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.949
Epoch: 0/2  Iteration: 37/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.920
Epoch: 0/2  Iteration: 38/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.918
Epoch: 0/2  Iteration: 39/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.921
Epoch: 0/2  Iteration: 40/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.912
Epoch: 0/2  Iteration: 41/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.926
Epoch: 0/2  Iteration: 42/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 0/2  Iteration: 43/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 0/2  Iteration: 44/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.893
Epoch: 0/2  Iteration: 45/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.877
Epoch: 0/2  Iteration: 46/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.865
Epoch: 0/2  Iteration: 47/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.877
Epoch: 0/2  Iteration: 48/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.876
Epoch: 0/2  Iteration: 49/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.880
Epoch: 0/2  Iteration: 50/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.866
Epoch: 0/2  Iteration: 51/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.856
Epoch: 0/2  Iteration: 52/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.848
Epoch: 0/2  Iteration: 53/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.846
Epoch: 0/2  Iteration: 54/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.860
Epoch: 0/2  Iteration: 55/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.846
Epoch: 0/2  Iteration: 56/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.845
Epoch: 0/2  Iteration: 57/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.821
Epoch: 0/2  Iteration: 58/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.824
Epoch: 0/2  Iteration: 59/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.853
Epoch: 0/2  Iteration: 60/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.821
Epoch: 0/2  Iteration: 61/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.827
Epoch: 0/2  Iteration: 62/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.822
Epoch: 0/2  Iteration: 63/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.823
Epoch: 0/2  Iteration: 64/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.799
Epoch: 0/2  Iteration: 65/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.810
Epoch: 0/2  Iteration: 66/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.811
Epoch: 0/2  Iteration: 67/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.791
Epoch: 0/2  Iteration: 68/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.782
Epoch: 0/2  Iteration: 69/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.779
Epoch: 0/2  Iteration: 70/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.779
Epoch: 0/2  Iteration: 71/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.755
Epoch: 0/2  Iteration: 72/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.773
Epoch: 0/2  Iteration: 73/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.760
Epoch: 0/2  Iteration: 74/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.769
Epoch: 0/2  Iteration: 75/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.732
Epoch: 0/2  Iteration: 76/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.762
Epoch: 0/2  Iteration: 77/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.709
Epoch: 0/2  Iteration: 78/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.734
Epoch: 0/2  Iteration: 79/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.764
Epoch: 0/2  Iteration: 80/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.706
Epoch: 0/2  Iteration: 81/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.745
Epoch: 0/2  Iteration: 82/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.703
Epoch: 0/2  Iteration: 83/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.721
Epoch: 0/2  Iteration: 84/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.697
Epoch: 0/2  Iteration: 85/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.693
Epoch: 0/2  Iteration: 86/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.711
Epoch: 0/2  Iteration: 87/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.676
Epoch: 0/2  Iteration: 88/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.682
Epoch: 0/2  Iteration: 89/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.672
Epoch: 0/2  Iteration: 90/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.670
Epoch: 0/2  Iteration: 91/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.655
Epoch: 0/2  Iteration: 92/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.649
Epoch: 0/2  Iteration: 93/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.645
Epoch: 0/2  Iteration: 94/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.661
Epoch: 0/2  Iteration: 95/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.609
Epoch: 0/2  Iteration: 96/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.652
Epoch: 0/2  Iteration: 97/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.597
Epoch: 0/2  Iteration: 98/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.634
Epoch: 0/2  Iteration: 99/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.657
Epoch: 0/2  Iteration: 100/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.655
Summary Epoch: 0/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.857
Epoch: 1/2  Iteration: 1/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.612
Epoch: 1/2  Iteration: 2/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.567
Epoch: 1/2  Iteration: 3/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.571
Epoch: 1/2  Iteration: 4/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.600
Epoch: 1/2  Iteration: 5/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.572
Epoch: 1/2  Iteration: 6/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.602
Epoch: 1/2  Iteration: 7/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.593
Epoch: 1/2  Iteration: 8/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.573
Epoch: 1/2  Iteration: 9/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.546
Epoch: 1/2  Iteration: 10/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.561
Epoch: 1/2  Iteration: 11/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.534
Epoch: 1/2  Iteration: 12/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.535
Epoch: 1/2  Iteration: 13/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.539
Epoch: 1/2  Iteration: 14/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.541
Epoch: 1/2  Iteration: 15/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.531
Epoch: 1/2  Iteration: 16/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.576
Epoch: 1/2  Iteration: 17/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.511
Epoch: 1/2  Iteration: 18/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.550
Epoch: 1/2  Iteration: 19/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.496
Epoch: 1/2  Iteration: 20/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.520
Epoch: 1/2  Iteration: 21/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.563
Epoch: 1/2  Iteration: 22/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.508
Epoch: 1/2  Iteration: 23/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.494
Epoch: 1/2  Iteration: 24/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.479
Epoch: 1/2  Iteration: 25/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.481
Epoch: 1/2  Iteration: 26/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.447
Epoch: 1/2  Iteration: 27/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.530
Epoch: 1/2  Iteration: 28/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.526
Epoch: 1/2  Iteration: 29/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.431
Epoch: 1/2  Iteration: 30/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.470
Epoch: 1/2  Iteration: 31/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.463
Epoch: 1/2  Iteration: 32/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.425
Epoch: 1/2  Iteration: 33/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.445
Epoch: 1/2  Iteration: 34/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.463
Epoch: 1/2  Iteration: 35/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.468
Epoch: 1/2  Iteration: 36/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.455
Epoch: 1/2  Iteration: 37/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.488
Epoch: 1/2  Iteration: 38/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.478
Epoch: 1/2  Iteration: 39/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.429
Epoch: 1/2  Iteration: 40/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.441
Epoch: 1/2  Iteration: 41/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.401
Epoch: 1/2  Iteration: 42/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.447
Epoch: 1/2  Iteration: 43/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.412
Epoch: 1/2  Iteration: 44/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.406
Epoch: 1/2  Iteration: 45/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.430
Epoch: 1/2  Iteration: 46/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.463
Epoch: 1/2  Iteration: 47/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.443
Epoch: 1/2  Iteration: 48/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.415
Epoch: 1/2  Iteration: 49/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.374
Epoch: 1/2  Iteration: 50/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.432
Epoch: 1/2  Iteration: 51/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.360
Epoch: 1/2  Iteration: 52/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.382
Epoch: 1/2  Iteration: 53/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.434
Epoch: 1/2  Iteration: 54/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.378
Epoch: 1/2  Iteration: 55/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.447
Epoch: 1/2  Iteration: 56/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.378
Epoch: 1/2  Iteration: 57/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.462
Epoch: 1/2  Iteration: 58/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.393
Epoch: 1/2  Iteration: 59/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.397
Epoch: 1/2  Iteration: 60/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.360
Epoch: 1/2  Iteration: 61/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.353
Epoch: 1/2  Iteration: 62/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.369
Epoch: 1/2  Iteration: 63/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.317
Epoch: 1/2  Iteration: 64/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.389
Epoch: 1/2  Iteration: 65/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.393
Epoch: 1/2  Iteration: 66/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.321
Epoch: 1/2  Iteration: 67/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.342
Epoch: 1/2  Iteration: 68/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.325
Epoch: 1/2  Iteration: 69/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.345
Epoch: 1/2  Iteration: 70/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.334
Epoch: 1/2  Iteration: 71/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.289
Epoch: 1/2  Iteration: 72/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.370
Epoch: 1/2  Iteration: 73/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.358
Epoch: 1/2  Iteration: 74/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.335
Epoch: 1/2  Iteration: 75/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.295
Epoch: 1/2  Iteration: 76/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.320
Epoch: 1/2  Iteration: 77/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.379
Epoch: 1/2  Iteration: 78/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.329
Epoch: 1/2  Iteration: 79/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.276
Epoch: 1/2  Iteration: 80/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.260
Epoch: 1/2  Iteration: 81/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.343
Epoch: 1/2  Iteration: 82/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.323
Epoch: 1/2  Iteration: 83/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.356
Epoch: 1/2  Iteration: 84/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.339
Epoch: 1/2  Iteration: 85/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.230
Epoch: 1/2  Iteration: 86/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.323
Epoch: 1/2  Iteration: 87/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.274
Epoch: 1/2  Iteration: 88/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.225
Epoch: 1/2  Iteration: 89/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.316
Epoch: 1/2  Iteration: 90/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.294
Epoch: 1/2  Iteration: 91/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.284
Epoch: 1/2  Iteration: 92/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.287
Epoch: 1/2  Iteration: 93/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.279
Epoch: 1/2  Iteration: 94/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.348
Epoch: 1/2  Iteration: 95/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.241
Epoch: 1/2  Iteration: 96/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.221
Epoch: 1/2  Iteration: 97/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.282
Epoch: 1/2  Iteration: 98/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.275
Epoch: 1/2  Iteration: 99/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.284
Epoch: 1/2  Iteration: 100/357;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.186
Summary Epoch: 1/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.412
None
Experiment ended
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7effacc1e048>}
data : /data/imagenet
data_backend : pytorch
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 256
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Epoch: 0/2  Iteration: 1/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.104
Epoch: 0/2  Iteration: 2/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.021
Epoch: 0/2  Iteration: 3/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.979
Epoch: 0/2  Iteration: 4/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.964
Epoch: 0/2  Iteration: 5/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.979
Epoch: 0/2  Iteration: 6/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.013
Epoch: 0/2  Iteration: 7/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.996
Epoch: 0/2  Iteration: 8/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.041
Epoch: 0/2  Iteration: 9/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.004
Epoch: 0/2  Iteration: 10/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.016
Epoch: 0/2  Iteration: 11/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.013
Epoch: 0/2  Iteration: 12/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.030
Epoch: 0/2  Iteration: 13/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.043
Epoch: 0/2  Iteration: 14/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.046
Epoch: 0/2  Iteration: 15/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.027
Epoch: 0/2  Iteration: 16/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.078
Epoch: 0/2  Iteration: 17/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.072
Epoch: 0/2  Iteration: 18/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.065
Epoch: 0/2  Iteration: 19/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.036
Epoch: 0/2  Iteration: 20/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.028
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
Epoch: 0/2  Iteration: 21/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.995
Epoch: 0/2  Iteration: 22/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.022
Epoch: 0/2  Iteration: 23/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.039
Epoch: 0/2  Iteration: 24/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.070
Epoch: 0/2  Iteration: 25/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.033
Epoch: 0/2  Iteration: 26/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.036
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
Epoch: 0/2  Iteration: 27/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.019
Epoch: 0/2  Iteration: 28/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.981
Epoch: 0/2  Iteration: 29/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.959
Epoch: 0/2  Iteration: 30/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.988
Epoch: 0/2  Iteration: 31/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.970
Epoch: 0/2  Iteration: 32/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.963
Epoch: 0/2  Iteration: 33/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.965
Epoch: 0/2  Iteration: 34/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.964
Epoch: 0/2  Iteration: 35/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.001
Epoch: 0/2  Iteration: 36/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.974
Epoch: 0/2  Iteration: 37/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.981
Epoch: 0/2  Iteration: 38/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.954
Epoch: 0/2  Iteration: 39/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.980
Epoch: 0/2  Iteration: 40/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.960
Epoch: 0/2  Iteration: 41/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.964
Epoch: 0/2  Iteration: 42/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.965
Epoch: 0/2  Iteration: 43/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.944
Epoch: 0/2  Iteration: 44/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.988
Epoch: 0/2  Iteration: 45/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.949
Epoch: 0/2  Iteration: 46/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.950
Epoch: 0/2  Iteration: 47/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.031
Epoch: 0/2  Iteration: 48/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.950
Epoch: 0/2  Iteration: 49/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.979
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
Epoch: 0/2  Iteration: 50/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.935
Epoch: 0/2  Iteration: 51/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.923
Epoch: 0/2  Iteration: 52/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 0/2  Iteration: 53/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.904
Epoch: 0/2  Iteration: 54/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 0/2  Iteration: 55/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.922
Epoch: 0/2  Iteration: 56/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.922
Epoch: 0/2  Iteration: 57/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.926
Epoch: 0/2  Iteration: 58/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.927
Epoch: 0/2  Iteration: 59/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 0/2  Iteration: 60/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.898
Epoch: 0/2  Iteration: 61/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 0/2  Iteration: 62/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.885
Epoch: 0/2  Iteration: 63/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 0/2  Iteration: 64/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.897
Epoch: 0/2  Iteration: 65/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.928
Epoch: 0/2  Iteration: 66/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 0/2  Iteration: 67/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.887
Epoch: 0/2  Iteration: 68/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.931
Epoch: 0/2  Iteration: 69/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.882
Epoch: 0/2  Iteration: 70/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.880
Epoch: 0/2  Iteration: 71/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.857
Epoch: 0/2  Iteration: 72/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.855
Epoch: 0/2  Iteration: 73/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.873
Epoch: 0/2  Iteration: 74/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.855
Epoch: 0/2  Iteration: 75/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.834
Epoch: 0/2  Iteration: 76/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.831
Epoch: 0/2  Iteration: 77/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.845
Epoch: 0/2  Iteration: 78/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.837
Epoch: 0/2  Iteration: 79/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.827
Epoch: 0/2  Iteration: 80/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.820
Epoch: 0/2  Iteration: 81/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.802
Epoch: 0/2  Iteration: 82/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.800
Epoch: 0/2  Iteration: 83/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.806
Epoch: 0/2  Iteration: 84/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.780
Epoch: 0/2  Iteration: 85/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.745
Epoch: 0/2  Iteration: 86/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.763
Epoch: 0/2  Iteration: 87/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.731
Epoch: 0/2  Iteration: 88/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.718
Epoch: 0/2  Iteration: 89/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.748
Epoch: 0/2  Iteration: 90/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.746
Epoch: 0/2  Iteration: 91/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.718
Epoch: 0/2  Iteration: 92/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.712
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
Epoch: 0/2  Iteration: 93/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.715
Epoch: 0/2  Iteration: 94/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.698
Epoch: 0/2  Iteration: 95/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.709
Epoch: 0/2  Iteration: 96/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.680
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1835008 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
Epoch: 0/2  Iteration: 97/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.686
Epoch: 0/2  Iteration: 98/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.706
Epoch: 0/2  Iteration: 99/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.660
Epoch: 0/2  Iteration: 100/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.654
Summary Epoch: 0/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.913
Epoch: 1/2  Iteration: 1/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.629
Epoch: 1/2  Iteration: 2/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.635
Epoch: 1/2  Iteration: 3/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.653
Epoch: 1/2  Iteration: 4/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.648
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19660800 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18481152 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 37093376 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 39976960 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 34865152 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. 
  warnings.warn(str(msg))
Epoch: 1/2  Iteration: 5/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.618
Epoch: 1/2  Iteration: 6/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.606
Epoch: 1/2  Iteration: 7/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.653
Epoch: 1/2  Iteration: 8/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.607
Epoch: 1/2  Iteration: 9/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.635
Epoch: 1/2  Iteration: 10/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.637
Epoch: 1/2  Iteration: 11/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.600
Epoch: 1/2  Iteration: 12/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.662
Epoch: 1/2  Iteration: 13/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.573
Epoch: 1/2  Iteration: 14/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.569
Epoch: 1/2  Iteration: 15/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.580
Epoch: 1/2  Iteration: 16/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.576
Epoch: 1/2  Iteration: 17/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.565
Epoch: 1/2  Iteration: 18/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.548
Epoch: 1/2  Iteration: 19/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.572
Epoch: 1/2  Iteration: 20/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.543
Epoch: 1/2  Iteration: 21/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.524
Epoch: 1/2  Iteration: 22/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.531
Epoch: 1/2  Iteration: 23/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.501
Epoch: 1/2  Iteration: 24/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.514
Epoch: 1/2  Iteration: 25/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.577
Epoch: 1/2  Iteration: 26/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.545
Epoch: 1/2  Iteration: 27/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.553
Epoch: 1/2  Iteration: 28/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.514
Epoch: 1/2  Iteration: 29/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.520
Epoch: 1/2  Iteration: 30/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.497
Epoch: 1/2  Iteration: 31/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.522
Epoch: 1/2  Iteration: 32/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.517
Epoch: 1/2  Iteration: 33/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.511
Epoch: 1/2  Iteration: 34/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.517
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1835008 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
Epoch: 1/2  Iteration: 35/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.444
Epoch: 1/2  Iteration: 36/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.500
Epoch: 1/2  Iteration: 37/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.474
Epoch: 1/2  Iteration: 38/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.491
Epoch: 1/2  Iteration: 39/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.474
Epoch: 1/2  Iteration: 40/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.532
Epoch: 1/2  Iteration: 41/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.462
Epoch: 1/2  Iteration: 42/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.483
Epoch: 1/2  Iteration: 43/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.499
Epoch: 1/2  Iteration: 44/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.441
Epoch: 1/2  Iteration: 45/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.457
Epoch: 1/2  Iteration: 46/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.415
Epoch: 1/2  Iteration: 47/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.518
Epoch: 1/2  Iteration: 48/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.481
Epoch: 1/2  Iteration: 49/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.437
Epoch: 1/2  Iteration: 50/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.408
Epoch: 1/2  Iteration: 51/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.453
Epoch: 1/2  Iteration: 52/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.421
Epoch: 1/2  Iteration: 53/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.394
Epoch: 1/2  Iteration: 54/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.364
Epoch: 1/2  Iteration: 55/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.397
Epoch: 1/2  Iteration: 56/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.360
Epoch: 1/2  Iteration: 57/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.365
Epoch: 1/2  Iteration: 58/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.355
Epoch: 1/2  Iteration: 59/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.372
Epoch: 1/2  Iteration: 60/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.412
Epoch: 1/2  Iteration: 61/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.432
Epoch: 1/2  Iteration: 62/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.392
Epoch: 1/2  Iteration: 63/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.360
Epoch: 1/2  Iteration: 64/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.359
Epoch: 1/2  Iteration: 65/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.366
Epoch: 1/2  Iteration: 66/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.382
Epoch: 1/2  Iteration: 67/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.378
Epoch: 1/2  Iteration: 68/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.340
Epoch: 1/2  Iteration: 69/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.333
Epoch: 1/2  Iteration: 70/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.343
Epoch: 1/2  Iteration: 71/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.291
Epoch: 1/2  Iteration: 72/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.360
Epoch: 1/2  Iteration: 73/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.476
Epoch: 1/2  Iteration: 74/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.375
Epoch: 1/2  Iteration: 75/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.280
Epoch: 1/2  Iteration: 76/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.320
Epoch: 1/2  Iteration: 77/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.303
Epoch: 1/2  Iteration: 78/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.298
Epoch: 1/2  Iteration: 79/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.348
Epoch: 1/2  Iteration: 80/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.325
Epoch: 1/2  Iteration: 81/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.333
Epoch: 1/2  Iteration: 82/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.264
Epoch: 1/2  Iteration: 83/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.301
Epoch: 1/2  Iteration: 84/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.314
Epoch: 1/2  Iteration: 85/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.333
Epoch: 1/2  Iteration: 86/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.273
Epoch: 1/2  Iteration: 87/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.392
Epoch: 1/2  Iteration: 88/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.303
Epoch: 1/2  Iteration: 89/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.339
Epoch: 1/2  Iteration: 90/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.375
Epoch: 1/2  Iteration: 91/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.376
Epoch: 1/2  Iteration: 92/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.294
Epoch: 1/2  Iteration: 93/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.252
Epoch: 1/2  Iteration: 94/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.363
Epoch: 1/2  Iteration: 95/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.303
Epoch: 1/2  Iteration: 96/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.303
Epoch: 1/2  Iteration: 97/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.277
Epoch: 1/2  Iteration: 98/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.278
Epoch: 1/2  Iteration: 99/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.252
Epoch: 1/2  Iteration: 100/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.281
/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:754: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0
  " Skipping tag %s" % (size, len(data), tag))
Summary Epoch: 1/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.441
None
Experiment ended
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']

['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '224', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_224BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
Job ended sucessfully
train.total_ips
[[181.55609969188794, 2239.6774089063033, 6215.248109880386, 6220.955597371473, 6221.4319091012185, 6175.954958426766, 6204.31770806033, 6189.162136079024, 6224.110911540561, 6193.481822564098, 6188.206703526554, 6214.076529730651, 6199.793676554105, 6209.645993162625, 6219.287793967793, 6223.866099224066, 6211.593521298913, 6223.927944728035, 6207.179338782232, 6215.484534871894, 6209.217649554168, 6200.757806228813, 6220.983916570104, 5907.9719166302475, 6214.906353371537, 6214.777883201388, 6216.787764921128, 6175.678399689088, 6220.214240995672, 6173.61133694355, 6212.201893036496, 6203.2679951850805, 5963.800570101225, 6212.468895471858, 6191.721600448139, 6189.8272912829525, 6208.9714428508, 6194.957097972761, 6185.991235639811, 6204.202478315564, 6210.271942783677, 5899.548375880131, 6177.350816201405, 6179.290836863013, 6192.609239571044, 6183.751915815593, 6204.676227973902, 6168.109303052709, 6189.493421567311, 6207.932973222988, 6199.036904189975, 6206.582200629478, 6162.399804539857, 6219.172007493265, 6208.548320695181, 6210.682470062899, 6187.834801561738, 6194.446542539164, 6169.187658001352, 6196.823894260953, 6188.3570053599215, 6181.061788062288, 6205.677742366948, 6164.484644339436, 6210.466936474072, 6204.581472254279, 6180.571308280569, 6182.904959605673, 5898.918678082775, 6210.497726070862, 6191.196278787789, 6206.823092324125, 6202.643456589418, 6177.602137612504, 6141.134428648524, 6197.066583777393, 6171.882661691624, 5897.601840481651, 6187.715089207505, 6186.276356330585, 6209.392057783207, 6190.015905363376, 6174.838726320191, 6200.036598745177, 6197.557130100011, 6166.156061440117, 5874.109073061852, 6203.790246944303, 6172.653095281113, 6167.074335708832, 6197.033372510398, 6177.457434908643, 6176.437092514344, 6179.730303950905, 6177.777313113878, 6216.546099147066, 6181.70995068576, 6169.326909715169, 6195.398796313354, 6190.334536338045], [3808.636031985439, 6174.699225676757, 6204.066768771959, 6189.7737677593195, 6211.655123141087, 6160.528441100883, 6160.69759996328, 6188.948093546565, 6173.735575238829, 6175.790035097406, 6187.2006335214855, 6203.777445604848, 5882.455469287146, 6173.928281263027, 6171.918137961332, 6202.070220388164, 6193.862059900757, 6194.53588366505, 6202.395211834091, 6194.385281542261, 6166.935185663802, 5901.1556405584915, 6179.328938470968, 6194.048367717276, 6173.951102509931, 6168.375059755626, 6165.698291310288, 6187.024923209515, 6201.15172796156, 6180.3705643966005, 6183.818054294603, 6210.005129154219, 6171.852253785049, 6186.441840213474, 6179.214635056689, 6188.165944965761, 6024.818286569914, 6181.73537159781, 6135.124169002174, 5868.009680874651, 6202.541085210545, 6174.8742365813305, 6160.195200072124, 6167.261565677887, 6153.132415844811, 6192.655158861919, 6194.474620901035, 6201.722235813697, 6152.369365162324, 6188.2398202525455, 6168.332030926219, 6186.411288676425, 6164.436613977231, 6175.543935123943, 6185.003699304287, 6160.058884587504, 6157.994695051487, 6195.797144780179, 6172.506089814395, 6173.9967455098795, 6202.267258381015, 6186.920520359682, 6186.487668084847, 6168.840821971213, 6158.529535561605, 6158.799513929461, 5889.73391325403, 6177.807779432603, 6172.5897299971875, 6171.094686845092, 6176.736561052878, 6196.632310700871, 6173.061198878595, 6192.7929208206315, 6147.473223476104, 6180.078365593732, 6170.248661375243, 6167.55508418423, 6190.551224138577, 6186.215256827111, 6204.21528140917, 6179.925925012354, 6183.601837591649, 6170.051119975931, 5871.952200597492, 6178.973341735074, 6186.151612794371, 6189.335419449299, 6193.127146599738, 6159.021569953005, 6187.513881005371, 6175.003598843737, 6172.447796481975, 6164.800652225086, 6168.046031022441, 6180.271467793274, 6184.769587447116, 6199.3948140373595, 6167.924552363032, 6210.384832375139], []]
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_256BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
Job ended sucessfully
train.total_ips
[[200.1484416531045, 1938.0090904373526, 6287.994225835142, 6273.118309064068, 6246.427886477035, 6248.102164158315, 6260.718714115842, 6260.399314484699, 6185.854730684629, 6253.012036229893, 6267.477085593668, 6228.404053206493, 6194.296582871161, 6288.512098157174, 6265.918100398425, 6171.4487438958595, 6169.4807268694785, 6182.337590590108, 6265.47706208887, 6010.8858685726245, 6269.931429493208, 6270.650026079241, 6206.822131282875, 6228.191803666178, 6267.275882623754, 6259.84956716345, 6266.905520025797, 6231.485558295302, 6226.5439750298465, 6187.079990766127, 6263.503433833312, 6208.986830197735, 6254.919846487515, 6228.365666579778, 5942.607117000724, 6262.731681461481, 6218.556481790494, 6240.834543245898, 6261.683955315, 6248.3748587922, 6249.431775365047, 6253.608386451188, 6243.7490924143685, 6200.240859898392, 6276.024120865894, 6234.819001608435, 6273.876585553614, 6209.063126919566, 6225.4428990637125, 6252.204185878936, 5891.611756975681, 6267.943560350394, 6224.777478453157, 6236.385186475871, 6277.292246352346, 6269.242738315144, 6251.8083016495, 6222.374126896109, 5791.507247529826, 6243.651518730734, 6266.251776849707, 6267.632569464357, 6247.749968815562, 6251.858353208669, 6166.285374845169, 6229.0860592137515, 5895.629131218555, 6223.715355957206, 6245.975962625656, 6238.0495540196325, 6243.932902287885, 6203.628313892983, 6227.611578225813, 6241.335606582153, 5751.548354719905, 6264.220557665725, 6267.772054206791, 6251.228217050992, 6248.508942382708, 6225.767766222452, 6220.851011656399, 6253.512780668563, 5797.610942247189, 6215.77109579307, 6230.986075199652, 6168.754119057143, 6229.178660948445, 6221.11907993366, 6235.744585151047, 6237.537694729385, 5801.610814987316, 6236.242567725275, 6254.525895317807, 6260.654831582366, 6224.270049874245, 6246.655008579217, 6269.796424947995, 6231.774888295128, 6244.8203342785455, 6196.287170882855], [1663.5751998363137, 6067.012815337865, 5594.260981751434, 6159.703609154866, 6211.705496388831, 6232.358150738602, 6190.105118729859, 6170.160969160812, 6189.71928940905, 6251.121311246355, 5941.743899204014, 6181.585708986144, 6196.653703610858, 6217.012736649967, 6184.732372928522, 6237.804938215125, 6206.781767819073, 6193.155531939514, 5884.195944531954, 6209.610723117928, 6237.678107943152, 6246.468767236549, 6218.212110693705, 6222.063134502255, 6217.433477479003, 6197.858650227425, 5875.717432613422, 6242.231372720006, 6242.669144373543, 6226.7967359448385, 6179.2689286512, 6240.777866938192, 6270.830845422478, 6245.011017548324, 6168.964551883075, 6218.67578263427, 6249.315838025812, 6241.049922603853, 6187.5033752403615, 6223.749175926587, 6196.238005156839, 6225.621120598592, 5970.02910810978, 6223.417756074942, 6186.008418508621, 6186.716817626588, 6217.471729469158, 6238.434636285235, 6253.412625364952, 6200.319179559435, 6254.496294055307, 6220.932105504626, 6211.665069386418, 6237.2455649143185, 6247.020709867677, 6230.583834812111, 6245.131335603118, 6173.908312810382, 6211.6471019986975, 6239.184550528337, 6260.376501472366, 6200.59890878734, 6187.149065330021, 6228.060848400304, 6267.609703705433, 6228.47405356746, 5853.728981187853, 6234.714918937201, 6252.122274683516, 6237.9974583053145, 6180.789536757449, 6223.284747149059, 6236.788176295523, 6238.817500488432, 6209.033954422163, 6174.764853603405, 6213.543234546406, 6247.661358174825, 6251.039428422143, 6229.858577507211, 6221.51108690409, 6213.781456242239, 6238.987425693566, 6242.603361293239, 6241.5918374761395, 6267.906971585515, 6252.147302876629, 6215.699131821582, 6192.642084550033, 6258.082361799326, 5891.3147656058445, 6210.079847486796, 6245.962337796431, 6214.484991072488, 6198.171700043727, 6230.728454589866, 6161.795780464807, 6240.743861647685, 5943.197126764033, 6250.682353403464], []]=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7fdd17bab048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-gpu
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 256
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Epoch: 0/2  Iteration: 1/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.081
Epoch: 0/2  Iteration: 2/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.014
Epoch: 0/2  Iteration: 3/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.985
Epoch: 0/2  Iteration: 4/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.959
Epoch: 0/2  Iteration: 5/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.973
Epoch: 0/2  Iteration: 6/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.009
Epoch: 0/2  Iteration: 7/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.020
Epoch: 0/2  Iteration: 8/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.032
Epoch: 0/2  Iteration: 9/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.015
Epoch: 0/2  Iteration: 10/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.007
Epoch: 0/2  Iteration: 11/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.996
Epoch: 0/2  Iteration: 12/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.032
Epoch: 0/2  Iteration: 13/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.026
Epoch: 0/2  Iteration: 14/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.015
Epoch: 0/2  Iteration: 15/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.016
Epoch: 0/2  Iteration: 16/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.029
Epoch: 0/2  Iteration: 17/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.030
Epoch: 0/2  Iteration: 18/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.036
Epoch: 0/2  Iteration: 19/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.023
Epoch: 0/2  Iteration: 20/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.032
Epoch: 0/2  Iteration: 21/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.102
Epoch: 0/2  Iteration: 22/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.046
Epoch: 0/2  Iteration: 23/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.068
Epoch: 0/2  Iteration: 24/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.061
Epoch: 0/2  Iteration: 25/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.109
Epoch: 0/2  Iteration: 26/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.207
Epoch: 0/2  Iteration: 27/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.101
Epoch: 0/2  Iteration: 28/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.238
Epoch: 0/2  Iteration: 29/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.386
Epoch: 0/2  Iteration: 30/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.252
Epoch: 0/2  Iteration: 31/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.289
Epoch: 0/2  Iteration: 32/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.283
Epoch: 0/2  Iteration: 33/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.200
Epoch: 0/2  Iteration: 34/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.247
Epoch: 0/2  Iteration: 35/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.205
Epoch: 0/2  Iteration: 36/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.096
Epoch: 0/2  Iteration: 37/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.149
Epoch: 0/2  Iteration: 38/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.074
Epoch: 0/2  Iteration: 39/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.071
Epoch: 0/2  Iteration: 40/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.120
Epoch: 0/2  Iteration: 41/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.081
Epoch: 0/2  Iteration: 42/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.170
Epoch: 0/2  Iteration: 43/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.053
Epoch: 0/2  Iteration: 44/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.059
Epoch: 0/2  Iteration: 45/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.023
Epoch: 0/2  Iteration: 46/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.018
Epoch: 0/2  Iteration: 47/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.029
Epoch: 0/2  Iteration: 48/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.015
Epoch: 0/2  Iteration: 49/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.984
Epoch: 0/2  Iteration: 50/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.008
Epoch: 0/2  Iteration: 51/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.977
Epoch: 0/2  Iteration: 52/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.011
Epoch: 0/2  Iteration: 53/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.975
Epoch: 0/2  Iteration: 54/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.968
Epoch: 0/2  Iteration: 55/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.010
Epoch: 0/2  Iteration: 56/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.943
Epoch: 0/2  Iteration: 57/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.941
Epoch: 0/2  Iteration: 58/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.975
Epoch: 0/2  Iteration: 59/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.947
Epoch: 0/2  Iteration: 60/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.930
Epoch: 0/2  Iteration: 61/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.944
Epoch: 0/2  Iteration: 62/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.934
Epoch: 0/2  Iteration: 63/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.932
Epoch: 0/2  Iteration: 64/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.949
Epoch: 0/2  Iteration: 65/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 0/2  Iteration: 66/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.942
Epoch: 0/2  Iteration: 67/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.942
Epoch: 0/2  Iteration: 68/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.955
Epoch: 0/2  Iteration: 69/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.942
Epoch: 0/2  Iteration: 70/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.923
Epoch: 0/2  Iteration: 71/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.930
Epoch: 0/2  Iteration: 72/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.907
Epoch: 0/2  Iteration: 73/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.913
Epoch: 0/2  Iteration: 74/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.922
Epoch: 0/2  Iteration: 75/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 0/2  Iteration: 76/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.893
Epoch: 0/2  Iteration: 77/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.905
Epoch: 0/2  Iteration: 78/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.909
Epoch: 0/2  Iteration: 79/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.904
Epoch: 0/2  Iteration: 80/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.901
Epoch: 0/2  Iteration: 81/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.942
Epoch: 0/2  Iteration: 82/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.897
Epoch: 0/2  Iteration: 83/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.882
Epoch: 0/2  Iteration: 84/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.905
Epoch: 0/2  Iteration: 85/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.894
Epoch: 0/2  Iteration: 86/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.891
Epoch: 0/2  Iteration: 87/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.893
Epoch: 0/2  Iteration: 88/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.875
Epoch: 0/2  Iteration: 89/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.872
Epoch: 0/2  Iteration: 90/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.882
Epoch: 0/2  Iteration: 91/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.888
Epoch: 0/2  Iteration: 92/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.874
Epoch: 0/2  Iteration: 93/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.876
Epoch: 0/2  Iteration: 94/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.864
Epoch: 0/2  Iteration: 95/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.872
Epoch: 0/2  Iteration: 96/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.885
Epoch: 0/2  Iteration: 97/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.863
Epoch: 0/2  Iteration: 98/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.852
Epoch: 0/2  Iteration: 99/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.869
Epoch: 0/2  Iteration: 100/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.850
Summary Epoch: 0/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.999
Epoch: 1/2  Iteration: 1/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.841
Epoch: 1/2  Iteration: 2/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.833
Epoch: 1/2  Iteration: 3/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.848
Epoch: 1/2  Iteration: 4/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.883
Epoch: 1/2  Iteration: 5/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.831
Epoch: 1/2  Iteration: 6/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.826
Epoch: 1/2  Iteration: 7/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.846
Epoch: 1/2  Iteration: 8/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.815
Epoch: 1/2  Iteration: 9/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.823
Epoch: 1/2  Iteration: 10/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.813
Epoch: 1/2  Iteration: 11/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.803
Epoch: 1/2  Iteration: 12/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.783
Epoch: 1/2  Iteration: 13/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.779
Epoch: 1/2  Iteration: 14/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.803
Epoch: 1/2  Iteration: 15/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.797
Epoch: 1/2  Iteration: 16/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.778
Epoch: 1/2  Iteration: 17/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.773
Epoch: 1/2  Iteration: 18/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.776
Epoch: 1/2  Iteration: 19/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.766
Epoch: 1/2  Iteration: 20/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.781
Epoch: 1/2  Iteration: 21/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.761
Epoch: 1/2  Iteration: 22/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.749
Epoch: 1/2  Iteration: 23/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.720
Epoch: 1/2  Iteration: 24/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.721
Epoch: 1/2  Iteration: 25/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.747
Epoch: 1/2  Iteration: 26/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.734
Epoch: 1/2  Iteration: 27/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.717
Epoch: 1/2  Iteration: 28/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.756
Epoch: 1/2  Iteration: 29/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.720
Epoch: 1/2  Iteration: 30/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.712
Epoch: 1/2  Iteration: 31/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.697
Epoch: 1/2  Iteration: 32/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.678
Epoch: 1/2  Iteration: 33/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.716
Epoch: 1/2  Iteration: 34/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.698
Epoch: 1/2  Iteration: 35/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.702
Epoch: 1/2  Iteration: 36/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.678
Epoch: 1/2  Iteration: 37/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.717
Epoch: 1/2  Iteration: 38/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.696
Epoch: 1/2  Iteration: 39/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.680
Epoch: 1/2  Iteration: 40/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.678
Epoch: 1/2  Iteration: 41/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.669
Epoch: 1/2  Iteration: 42/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.661
Epoch: 1/2  Iteration: 43/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.670
Epoch: 1/2  Iteration: 44/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.661
Epoch: 1/2  Iteration: 45/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.658
Epoch: 1/2  Iteration: 46/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.643
Epoch: 1/2  Iteration: 47/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.631
Epoch: 1/2  Iteration: 48/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.652
Epoch: 1/2  Iteration: 49/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.642
Epoch: 1/2  Iteration: 50/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.648
Epoch: 1/2  Iteration: 51/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.650
Epoch: 1/2  Iteration: 52/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.628
Epoch: 1/2  Iteration: 53/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.598
Epoch: 1/2  Iteration: 54/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.625
Epoch: 1/2  Iteration: 55/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.606
Epoch: 1/2  Iteration: 56/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.591
Epoch: 1/2  Iteration: 57/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.616
Epoch: 1/2  Iteration: 58/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.622
Epoch: 1/2  Iteration: 59/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.589
Epoch: 1/2  Iteration: 60/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.577
Epoch: 1/2  Iteration: 61/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.596
Epoch: 1/2  Iteration: 62/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.556
Epoch: 1/2  Iteration: 63/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.579
Epoch: 1/2  Iteration: 64/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.569
Epoch: 1/2  Iteration: 65/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.528
Epoch: 1/2  Iteration: 66/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.566
Epoch: 1/2  Iteration: 67/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.558
Epoch: 1/2  Iteration: 68/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.611
Epoch: 1/2  Iteration: 69/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.613
Epoch: 1/2  Iteration: 70/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.591
Epoch: 1/2  Iteration: 71/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.570
Epoch: 1/2  Iteration: 72/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.568
Epoch: 1/2  Iteration: 73/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.549
Epoch: 1/2  Iteration: 74/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.553
Epoch: 1/2  Iteration: 75/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.535
Epoch: 1/2  Iteration: 76/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.508
Epoch: 1/2  Iteration: 77/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.527
Epoch: 1/2  Iteration: 78/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.496
Epoch: 1/2  Iteration: 79/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.537
Epoch: 1/2  Iteration: 80/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.546
Epoch: 1/2  Iteration: 81/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.484
Epoch: 1/2  Iteration: 82/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.547
Epoch: 1/2  Iteration: 83/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.535
Epoch: 1/2  Iteration: 84/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.503
Epoch: 1/2  Iteration: 85/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.491
Epoch: 1/2  Iteration: 86/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.496
Epoch: 1/2  Iteration: 87/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.528
Epoch: 1/2  Iteration: 88/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.483
Epoch: 1/2  Iteration: 89/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.461
Epoch: 1/2  Iteration: 90/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.488
Epoch: 1/2  Iteration: 91/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.463
Epoch: 1/2  Iteration: 92/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.527
Epoch: 1/2  Iteration: 93/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.456
Epoch: 1/2  Iteration: 94/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.499
Epoch: 1/2  Iteration: 95/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.478
Epoch: 1/2  Iteration: 96/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.437
Epoch: 1/2  Iteration: 97/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.503
Epoch: 1/2  Iteration: 98/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.465
Epoch: 1/2  Iteration: 99/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.430
Epoch: 1/2  Iteration: 100/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.531
Summary Epoch: 1/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.641
None
Experiment ended
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f8a77f44048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-cpu
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 256
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Epoch: 0/2  Iteration: 1/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.103
Epoch: 0/2  Iteration: 2/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.012
Epoch: 0/2  Iteration: 3/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.972
Epoch: 0/2  Iteration: 4/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.956
Epoch: 0/2  Iteration: 5/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.980
Epoch: 0/2  Iteration: 6/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.011
Epoch: 0/2  Iteration: 7/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.019
Epoch: 0/2  Iteration: 8/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.020
Epoch: 0/2  Iteration: 9/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.026
Epoch: 0/2  Iteration: 10/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.021
Epoch: 0/2  Iteration: 11/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.015
Epoch: 0/2  Iteration: 12/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.011
Epoch: 0/2  Iteration: 13/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.002
Epoch: 0/2  Iteration: 14/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.000
Epoch: 0/2  Iteration: 15/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.034
Epoch: 0/2  Iteration: 16/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.035
Epoch: 0/2  Iteration: 17/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.029
Epoch: 0/2  Iteration: 18/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.025
Epoch: 0/2  Iteration: 19/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.026
Epoch: 0/2  Iteration: 20/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.047
Epoch: 0/2  Iteration: 21/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.038
Epoch: 0/2  Iteration: 22/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.001
Epoch: 0/2  Iteration: 23/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.984
Epoch: 0/2  Iteration: 24/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.003
Epoch: 0/2  Iteration: 25/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.018
Epoch: 0/2  Iteration: 26/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 7.006
Epoch: 0/2  Iteration: 27/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.967
Epoch: 0/2  Iteration: 28/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.971
Epoch: 0/2  Iteration: 29/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.996
Epoch: 0/2  Iteration: 30/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.988
Epoch: 0/2  Iteration: 31/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.976
Epoch: 0/2  Iteration: 32/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.967
Epoch: 0/2  Iteration: 33/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.970
Epoch: 0/2  Iteration: 34/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.977
Epoch: 0/2  Iteration: 35/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.967
Epoch: 0/2  Iteration: 36/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.949
Epoch: 0/2  Iteration: 37/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.970
Epoch: 0/2  Iteration: 38/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.934
Epoch: 0/2  Iteration: 39/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.940
Epoch: 0/2  Iteration: 40/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.911
Epoch: 0/2  Iteration: 41/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.920
Epoch: 0/2  Iteration: 42/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.919
Epoch: 0/2  Iteration: 43/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.910
Epoch: 0/2  Iteration: 44/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.899
Epoch: 0/2  Iteration: 45/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.915
Epoch: 0/2  Iteration: 46/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.894
Epoch: 0/2  Iteration: 47/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.907
Epoch: 0/2  Iteration: 48/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.899
Epoch: 0/2  Iteration: 49/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.906
Epoch: 0/2  Iteration: 50/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.903
Epoch: 0/2  Iteration: 51/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.897
Epoch: 0/2  Iteration: 52/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.900
Epoch: 0/2  Iteration: 53/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.891
Epoch: 0/2  Iteration: 54/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.879
Epoch: 0/2  Iteration: 55/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.876
Epoch: 0/2  Iteration: 56/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.875
Epoch: 0/2  Iteration: 57/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.856
Epoch: 0/2  Iteration: 58/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.857
Epoch: 0/2  Iteration: 59/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.829
Epoch: 0/2  Iteration: 60/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.867
Epoch: 0/2  Iteration: 61/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.836
Epoch: 0/2  Iteration: 62/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.826
Epoch: 0/2  Iteration: 63/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.839
Epoch: 0/2  Iteration: 64/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.817
Epoch: 0/2  Iteration: 65/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.802
Epoch: 0/2  Iteration: 66/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.793
Epoch: 0/2  Iteration: 67/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.783
Epoch: 0/2  Iteration: 68/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.787
Epoch: 0/2  Iteration: 69/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.779
Epoch: 0/2  Iteration: 70/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.755
Epoch: 0/2  Iteration: 71/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.785
Epoch: 0/2  Iteration: 72/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.751
Epoch: 0/2  Iteration: 73/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.767
Epoch: 0/2  Iteration: 74/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.765
Epoch: 0/2  Iteration: 75/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.748
Epoch: 0/2  Iteration: 76/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.730
Epoch: 0/2  Iteration: 77/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.722
Epoch: 0/2  Iteration: 78/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.731
Epoch: 0/2  Iteration: 79/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.708
Epoch: 0/2  Iteration: 80/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.736
Epoch: 0/2  Iteration: 81/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.719
Epoch: 0/2  Iteration: 82/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.719
Epoch: 0/2  Iteration: 83/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.746
Epoch: 0/2  Iteration: 84/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.719
Epoch: 0/2  Iteration: 85/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.715
Epoch: 0/2  Iteration: 86/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.720
Epoch: 0/2  Iteration: 87/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.690
Epoch: 0/2  Iteration: 88/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.643
Epoch: 0/2  Iteration: 89/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.666
Epoch: 0/2  Iteration: 90/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.641
Epoch: 0/2  Iteration: 91/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.642
Epoch: 0/2  Iteration: 92/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.662
Epoch: 0/2  Iteration: 93/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.669
Epoch: 0/2  Iteration: 94/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.651
Epoch: 0/2  Iteration: 95/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.655
Epoch: 0/2  Iteration: 96/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.625
Epoch: 0/2  Iteration: 97/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.666
Epoch: 0/2  Iteration: 98/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.632
Epoch: 0/2  Iteration: 99/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.702
Epoch: 0/2  Iteration: 100/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.656
Summary Epoch: 0/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.867
Epoch: 1/2  Iteration: 1/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.629
Epoch: 1/2  Iteration: 2/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.605
Epoch: 1/2  Iteration: 3/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.582
Epoch: 1/2  Iteration: 4/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.602
Epoch: 1/2  Iteration: 5/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.592
Epoch: 1/2  Iteration: 6/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.574
Epoch: 1/2  Iteration: 7/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.603
Epoch: 1/2  Iteration: 8/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.572
Epoch: 1/2  Iteration: 9/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.590
Epoch: 1/2  Iteration: 10/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.566
Epoch: 1/2  Iteration: 11/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.605
Epoch: 1/2  Iteration: 12/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.594
Epoch: 1/2  Iteration: 13/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.542
Epoch: 1/2  Iteration: 14/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.572
Epoch: 1/2  Iteration: 15/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.554
Epoch: 1/2  Iteration: 16/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.601
Epoch: 1/2  Iteration: 17/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.529
Epoch: 1/2  Iteration: 18/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.535
Epoch: 1/2  Iteration: 19/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.548
Epoch: 1/2  Iteration: 20/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.587
Epoch: 1/2  Iteration: 21/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.507
Epoch: 1/2  Iteration: 22/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.513
Epoch: 1/2  Iteration: 23/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.524
Epoch: 1/2  Iteration: 24/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.509
Epoch: 1/2  Iteration: 25/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.499
Epoch: 1/2  Iteration: 26/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.505
Epoch: 1/2  Iteration: 27/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.532
Epoch: 1/2  Iteration: 28/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.488
Epoch: 1/2  Iteration: 29/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.530
Epoch: 1/2  Iteration: 30/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.524
Epoch: 1/2  Iteration: 31/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.508
Epoch: 1/2  Iteration: 32/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.509
Epoch: 1/2  Iteration: 33/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.467
Epoch: 1/2  Iteration: 34/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.481
Epoch: 1/2  Iteration: 35/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.438
Epoch: 1/2  Iteration: 36/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.493
Epoch: 1/2  Iteration: 37/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.479
Epoch: 1/2  Iteration: 38/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.443
Epoch: 1/2  Iteration: 39/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.433
Epoch: 1/2  Iteration: 40/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.539
Epoch: 1/2  Iteration: 41/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.465
Epoch: 1/2  Iteration: 42/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.432
Epoch: 1/2  Iteration: 43/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.439
Epoch: 1/2  Iteration: 44/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.409
Epoch: 1/2  Iteration: 45/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.397
Epoch: 1/2  Iteration: 46/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.446
Epoch: 1/2  Iteration: 47/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.369
Epoch: 1/2  Iteration: 48/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.419
Epoch: 1/2  Iteration: 49/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.437
Epoch: 1/2  Iteration: 50/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.420
Epoch: 1/2  Iteration: 51/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.447
Epoch: 1/2  Iteration: 52/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.450
Epoch: 1/2  Iteration: 53/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.379
Epoch: 1/2  Iteration: 54/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.395
Epoch: 1/2  Iteration: 55/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.366
Epoch: 1/2  Iteration: 56/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.375
Epoch: 1/2  Iteration: 57/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.424
Epoch: 1/2  Iteration: 58/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.378
Epoch: 1/2  Iteration: 59/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.372
Epoch: 1/2  Iteration: 60/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.405
Epoch: 1/2  Iteration: 61/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.365
Epoch: 1/2  Iteration: 62/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.293
Epoch: 1/2  Iteration: 63/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.325
Epoch: 1/2  Iteration: 64/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.394
Epoch: 1/2  Iteration: 65/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.325
Epoch: 1/2  Iteration: 66/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.386
Epoch: 1/2  Iteration: 67/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.355
Epoch: 1/2  Iteration: 68/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.291
Epoch: 1/2  Iteration: 69/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.347
Epoch: 1/2  Iteration: 70/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.324
Epoch: 1/2  Iteration: 71/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.313
Epoch: 1/2  Iteration: 72/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.452
Epoch: 1/2  Iteration: 73/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.293
Epoch: 1/2  Iteration: 74/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.337
Epoch: 1/2  Iteration: 75/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.323
Epoch: 1/2  Iteration: 76/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.299
Epoch: 1/2  Iteration: 77/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.259
Epoch: 1/2  Iteration: 78/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.265
Epoch: 1/2  Iteration: 79/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.281
Epoch: 1/2  Iteration: 80/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.259
Epoch: 1/2  Iteration: 81/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.325
Epoch: 1/2  Iteration: 82/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.314
Epoch: 1/2  Iteration: 83/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.259
Epoch: 1/2  Iteration: 84/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.371
Epoch: 1/2  Iteration: 85/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.258
Epoch: 1/2  Iteration: 86/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.209
Epoch: 1/2  Iteration: 87/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.269
Epoch: 1/2  Iteration: 88/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.273
Epoch: 1/2  Iteration: 89/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.281
Epoch: 1/2  Iteration: 90/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.324
Epoch: 1/2  Iteration: 91/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.286
Epoch: 1/2  Iteration: 92/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.258
Epoch: 1/2  Iteration: 93/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.211
Epoch: 1/2  Iteration: 94/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.252
Epoch: 1/2  Iteration: 95/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.336
Epoch: 1/2  Iteration: 96/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.322
Epoch: 1/2  Iteration: 97/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.301
Epoch: 1/2  Iteration: 98/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.240
Epoch: 1/2  Iteration: 99/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.300
Epoch: 1/2  Iteration: 100/312;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.259
Summary Epoch: 1/2;	train.top1 : 0.000	train.top5 : 0.000	train.loss : 6.419
None
Experiment ended
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']

['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
Job ended sucessfully
train.total_ips
[[208.12789704457225, 2205.49647592871, 6035.08638494519, 6082.105934240534, 6163.358655674423, 6209.494014190139, 6209.458104633419, 6167.861600460978, 6169.474080290678, 6180.427101702976, 6153.459855353192, 6182.891608550162, 6154.202705505546, 6148.916284265348, 6208.717562636969, 6198.900781471568, 6162.613593652532, 6156.335262667527, 6153.470875558178, 6124.27641158873, 6097.585963661944, 6161.174829508451, 6123.964232639694, 6150.686223467804, 6156.275698615401, 6189.788422917812, 6149.924408333748, 6184.476336458233, 6146.546953822552, 6144.706868425373, 6143.906983830101, 6165.754244371732, 6186.066331843577, 6188.270071417791, 6078.948802335353, 6168.293432045929, 6181.516758586545, 6196.081573946541, 6199.3414445008575, 6183.002869107928, 6183.844128506875, 6114.478713230545, 6126.8470940585175, 6163.716880173992, 6177.726853934483, 6135.463780667285, 6167.064531750035, 6162.766128777683, 6105.525892708959, 5950.727457378196, 6167.885958582223, 6144.524458827081, 6160.958299533872, 6170.989870950616, 6161.54605916277, 6182.553401042045, 6146.826250654312, 6072.983531060295, 6168.286788025102, 6179.113353064925, 6165.123645761786, 6155.554403261393, 6195.379965402254, 6162.56275028876, 6147.096774932249, 6172.477576633797, 6154.03516280556, 6187.995911137109, 6152.133311083307, 6138.414506205813, 6171.289128174843, 6187.3473847453715, 6173.857282907125, 6148.363937244696, 6122.722381251069, 6171.036420168164, 6166.770111253974, 6155.523525887792, 6158.129342491022, 6143.520301127763, 6133.468279231304, 6165.378082308783, 6143.2215341936535, 6185.685460179977, 6182.958364404315, 6154.200500937108, 6170.1720492669365, 6169.372167875712, 6175.959081622859, 6191.0018558732445, 6168.898097860726, 6187.053252639332, 6185.87032185494, 6206.775040626145, 6156.891249406884, 6156.783133009389, 6161.58583642192, 6147.365123349001, 6162.065413799473, 6158.656952309119], [5068.758971889712, 6149.512754429974, 6155.3581166610475, 6139.302910080326, 6180.551614474545, 6188.0115131028, 6159.339226219051, 6170.333823348247, 6178.604453376356, 6150.336117354175, 6163.595256076372, 6171.559593004459, 6185.271231969239, 6166.6926368483155, 6170.384795021704, 6156.295553171376, 6186.253443875346, 6125.315782042634, 5962.735460081646, 6137.129517638666, 6117.2764111325305, 6113.943414631369, 6172.885657022088, 6168.922464169347, 6162.99826193516, 6163.396245178756, 5906.024460340641, 6159.356892276043, 6144.825550364883, 6170.398092118496, 6134.896321605284, 6172.903400871687, 6147.136365848282, 6141.602986314631, 5912.479896038677, 6155.838930782116, 6165.541817800751, 6134.937946308528, 6148.35293532406, 6150.965896608565, 6005.739819441896, 6151.47025340455, 6176.785100531718, 5339.070604307836, 6155.38458153994, 6180.011354328505, 6083.062113565048, 6158.321390830555, 6165.634752624453, 6174.258888862134, 5949.451847685947, 6177.358114388428, 6170.032442837877, 6155.556608799933, 6181.196493025773, 6161.782520417785, 6141.622746341542, 6172.615075954643, 5919.702036179372, 6169.97261344504, 6152.410912554881, 6176.403150349106, 6154.6855440453855, 6148.544374361162, 6161.159362576947, 5997.994316874568, 6165.4732248469745, 6157.656998689248, 6173.249426329002, 6107.772496185279, 6134.883177079502, 6141.996015179927, 6151.003335100835, 6162.251076698371, 6170.493389655976, 6099.04064839189, 6186.41829004368, 6106.745582439738, 6169.095248970493, 6138.526365135764, 6193.264929559186, 6086.225676699214, 6152.413115841367, 6160.187311280078, 6152.5585362385955, 6165.371444566859, 6168.386449840367, 6181.972749455115, 6201.870316388044, 6062.544616856967, 6155.205948023583, 6178.051203416582, 6138.583392825878, 6150.4594206208785, 6159.11399287502, 5889.434515365782, 6173.546684298661, 6169.73330747628, 6152.426335593418, 6161.69191162388], []]
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '256', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_256BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
Job ended sucessfully
train.total_ips
[[227.57825988469457, 2119.646071191286, 6260.134693763029, 6224.617347611656, 6236.8221384911785, 6235.943768636739, 6268.782932433463, 6254.138824009086, 6259.797106698289, 6251.091742201267, 6252.900517706253, 6229.546836540958, 6239.803195544499, 6206.331078132451, 6256.054156429492, 6231.702553276385, 6244.659170595355, 6275.987437700853, 6165.362594266528, 6228.720196362081, 6240.898021932673, 6268.956781453672, 6243.7127855711715, 6256.311597279831, 6203.442389332887, 6237.521842021757, 6239.975440896849, 6193.619940291319, 6213.754486831478, 6228.815045567138, 6222.4349768703305, 6243.431421852394, 6206.770555838961, 6223.7198652652205, 6251.901580200171, 6242.764418878874, 6240.929761760319, 6219.569559066087, 6189.143980111009, 6204.876312902954, 6225.66172946431, 6224.989495340825, 6232.057463054464, 6227.37003763999, 6194.980074946127, 6225.948262628298, 6259.689907612395, 6240.385695096356, 6242.249517475525, 6224.488797827572, 6215.013308839676, 6237.9340386101285, 6221.28578950456, 6211.099146600048, 6235.115429995779, 6227.293290348492, 6216.724775754734, 6235.742321775465, 6224.43016284726, 6241.521541950937, 6207.654184055818, 6039.013160087092, 6210.1763746897595, 6205.241621234657, 6219.884805987354, 6223.248677911827, 6207.582407909922, 6230.118385480449, 6234.472827035609, 6228.0021461032275, 6239.896116198065, 6232.6995681700355, 6240.44463106995, 6242.753076523363, 6213.749991952445, 6229.881168644675, 6223.93857454781, 6188.149705376275, 6188.08060846801, 6208.825266858643, 6211.510104085166, 6248.386221585175, 6238.006518367039, 6207.869522452929, 6218.781581551724, 5952.240763389353, 6218.738811343095, 6225.192503767575, 6255.742066289523, 6217.919537771253, 6223.203591953243, 6214.889651949059, 6198.844864246789, 6182.9539139691915, 6217.640493868267, 6227.37003763999, 6208.446074826438, 6194.834876104162, 6239.846255991097, 6233.224202944876], [4071.421810094928, 5899.8444613328875, 6245.385607875499, 6232.851070005101, 6213.990477113677, 6213.907316587967, 6234.766959838432, 6214.563671004716, 6204.643255216111, 6241.487528555568, 6232.724441100306, 6195.797783200244, 6195.489441622754, 6232.392064704186, 6229.104127628716, 6204.9009642590645, 6223.782996263528, 6249.18626609005, 6248.02944960915, 6234.49997659323, 6232.104938128294, 6218.387667663378, 6186.057422029157, 6187.83766707379, 6191.349913399726, 5955.498837143599, 6202.951870792756, 6201.879271811522, 6206.1718949306605, 6225.048140859636, 6222.840673781575, 6237.272738626511, 6208.881364287385, 5945.88963334209, 6234.687767507521, 6247.899931010731, 6243.433690813215, 6236.550451282114, 6247.861303696376, 6221.770199087297, 6205.53076077569, 5952.510930286142, 6204.244408643972, 6214.347867952422, 6218.797339145311, 6228.126325344861, 6212.114287863179, 6214.644601013523, 6226.580082475632, 5984.926504333879, 6238.083529954285, 6164.398063833222, 6193.66013275011, 6237.256887265625, 6230.696818439811, 6219.087743380675, 6203.9173031026685, 6012.692962890763, 6234.785061225112, 6213.70953833378, 6201.0107161355645, 6203.063854493356, 6235.86454640818, 6224.046807507026, 6215.579945159209, 6010.069981815726, 6247.30921252395, 6192.2983456201055, 6210.358213152829, 6234.269212890303, 6225.282733985266, 6210.901547061314, 6210.616397164351, 5972.903803878662, 6215.645159936497, 6231.646042711403, 6233.80547475979, 6212.336675051095, 6187.813151112014, 6169.336720868425, 6209.197772767653, 6233.491076932678, 6228.776653874253, 6243.533526722018, 6215.217915592501, 6243.032110433465, 6226.713232301303, 6219.463733335747, 6201.341992176432, 5962.592666094003, 6215.42253581764, 6218.558732707443, 6228.964100154384, 6204.502084555223, 6181.105312373063, 6206.914072243539, 6216.367111476811, 6222.802355699974, 6248.008998947141, 6217.798015573568], []]=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7fbbf4f24048>}
data : /data/imagenet
data_backend : pytorch
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 448
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 4; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 2; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 15; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 1; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.31 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 11; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 9; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 10; 31.72 GiB total capacity; 30.18 GiB already allocated; 268.31 MiB free; 232.58 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 0; 31.72 GiB total capacity; 30.18 GiB already allocated; 268.38 MiB free; 232.58 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 5; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    main(args)
  File "main.py", line 282, in main
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    training, momentum, eps, torch.backends.cudnn.enabled
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 8; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 12; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 14; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 7; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
Traceback (most recent call last):
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
  File "main.py", line 297, in <module>
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    main(args)
  File "main.py", line 282, in main
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 13; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 6; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 3; 31.72 GiB total capacity; 30.18 GiB already allocated; 10.38 MiB free; 489.83 MiB cached)
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f4b7feb1048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-gpu
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 448
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 15; 31.72 GiB total capacity; 26.32 GiB already allocated; 2.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 9; 31.72 GiB total capacity; 26.32 GiB already allocated; 2.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 7; 31.72 GiB total capacity; 26.32 GiB already allocated; 2.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 5; 31.72 GiB total capacity; 26.32 GiB already allocated; 168.38 MiB free; 79.82 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 4; 31.72 GiB total capacity; 26.32 GiB already allocated; 2.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 11; 31.72 GiB total capacity; 26.32 GiB already allocated; 236.38 MiB free; 79.82 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 12; 31.72 GiB total capacity; 26.32 GiB already allocated; 34.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 6; 31.72 GiB total capacity; 26.32 GiB already allocated; 2.38 MiB free; 79.82 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 3; 31.72 GiB total capacity; 26.32 GiB already allocated; 106.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 301, in forward
    out = self.conv2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 172.00 MiB (GPU 1; 31.72 GiB total capacity; 25.99 GiB already allocated; 10.31 MiB free; 79.82 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
Traceback (most recent call last):
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
  File "main.py", line 297, in <module>
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    main(args)
  File "main.py", line 282, in main
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 8; 31.72 GiB total capacity; 26.32 GiB already allocated; 2.38 MiB free; 454.32 MiB cached)
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
Traceback (most recent call last):
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
  File "main.py", line 297, in <module>
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    main(args)
  File "main.py", line 282, in main
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    self.padding, self.dilation, self.groups)
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 13; 31.72 GiB total capacity; 26.32 GiB already allocated; 182.38 MiB free; 454.32 MiB cached)
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 0; 31.72 GiB total capacity; 26.32 GiB already allocated; 2.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    main(args)
  File "main.py", line 282, in main
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    self.padding, self.dilation, self.groups)
    loss, output = model_and_loss(input_var, target_var)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 10; 31.72 GiB total capacity; 26.32 GiB already allocated; 32.31 MiB free; 454.32 MiB cached)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 2; 31.72 GiB total capacity; 26.32 GiB already allocated; 180.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 301, in forward
    out = self.conv2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 172.00 MiB (GPU 14; 31.72 GiB total capacity; 25.99 GiB already allocated; 2.38 MiB free; 79.82 MiB cached)
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']

['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
CMD: "/opt/conda/bin/python multiproc.py --nproc_per_node 16 main.py -p 1 -j 3 --training-only  --workspace /data/workspace --epochs 2 --prof 100  -b 448 --data-backend pytorch --raport-file /data/workspace/./raport_16GPU_448BS_pytorch_trainingbench.json --no-checkpoints /data/imagenet --arch resnet50 -c fanin --label-smoothing 0.1 --mixup 0.1" exited with status 1
train.total_ips
[[227.57825988469457, 2119.646071191286, 6260.134693763029, 6224.617347611656, 6236.8221384911785, 6235.943768636739, 6268.782932433463, 6254.138824009086, 6259.797106698289, 6251.091742201267, 6252.900517706253, 6229.546836540958, 6239.803195544499, 6206.331078132451, 6256.054156429492, 6231.702553276385, 6244.659170595355, 6275.987437700853, 6165.362594266528, 6228.720196362081, 6240.898021932673, 6268.956781453672, 6243.7127855711715, 6256.311597279831, 6203.442389332887, 6237.521842021757, 6239.975440896849, 6193.619940291319, 6213.754486831478, 6228.815045567138, 6222.4349768703305, 6243.431421852394, 6206.770555838961, 6223.7198652652205, 6251.901580200171, 6242.764418878874, 6240.929761760319, 6219.569559066087, 6189.143980111009, 6204.876312902954, 6225.66172946431, 6224.989495340825, 6232.057463054464, 6227.37003763999, 6194.980074946127, 6225.948262628298, 6259.689907612395, 6240.385695096356, 6242.249517475525, 6224.488797827572, 6215.013308839676, 6237.9340386101285, 6221.28578950456, 6211.099146600048, 6235.115429995779, 6227.293290348492, 6216.724775754734, 6235.742321775465, 6224.43016284726, 6241.521541950937, 6207.654184055818, 6039.013160087092, 6210.1763746897595, 6205.241621234657, 6219.884805987354, 6223.248677911827, 6207.582407909922, 6230.118385480449, 6234.472827035609, 6228.0021461032275, 6239.896116198065, 6232.6995681700355, 6240.44463106995, 6242.753076523363, 6213.749991952445, 6229.881168644675, 6223.93857454781, 6188.149705376275, 6188.08060846801, 6208.825266858643, 6211.510104085166, 6248.386221585175, 6238.006518367039, 6207.869522452929, 6218.781581551724, 5952.240763389353, 6218.738811343095, 6225.192503767575, 6255.742066289523, 6217.919537771253, 6223.203591953243, 6214.889651949059, 6198.844864246789, 6182.9539139691915, 6217.640493868267, 6227.37003763999, 6208.446074826438, 6194.834876104162, 6239.846255991097, 6233.224202944876], [4071.421810094928, 5899.8444613328875, 6245.385607875499, 6232.851070005101, 6213.990477113677, 6213.907316587967, 6234.766959838432, 6214.563671004716, 6204.643255216111, 6241.487528555568, 6232.724441100306, 6195.797783200244, 6195.489441622754, 6232.392064704186, 6229.104127628716, 6204.9009642590645, 6223.782996263528, 6249.18626609005, 6248.02944960915, 6234.49997659323, 6232.104938128294, 6218.387667663378, 6186.057422029157, 6187.83766707379, 6191.349913399726, 5955.498837143599, 6202.951870792756, 6201.879271811522, 6206.1718949306605, 6225.048140859636, 6222.840673781575, 6237.272738626511, 6208.881364287385, 5945.88963334209, 6234.687767507521, 6247.899931010731, 6243.433690813215, 6236.550451282114, 6247.861303696376, 6221.770199087297, 6205.53076077569, 5952.510930286142, 6204.244408643972, 6214.347867952422, 6218.797339145311, 6228.126325344861, 6212.114287863179, 6214.644601013523, 6226.580082475632, 5984.926504333879, 6238.083529954285, 6164.398063833222, 6193.66013275011, 6237.256887265625, 6230.696818439811, 6219.087743380675, 6203.9173031026685, 6012.692962890763, 6234.785061225112, 6213.70953833378, 6201.0107161355645, 6203.063854493356, 6235.86454640818, 6224.046807507026, 6215.579945159209, 6010.069981815726, 6247.30921252395, 6192.2983456201055, 6210.358213152829, 6234.269212890303, 6225.282733985266, 6210.901547061314, 6210.616397164351, 5972.903803878662, 6215.645159936497, 6231.646042711403, 6233.80547475979, 6212.336675051095, 6187.813151112014, 6169.336720868425, 6209.197772767653, 6233.491076932678, 6228.776653874253, 6243.533526722018, 6215.217915592501, 6243.032110433465, 6226.713232301303, 6219.463733335747, 6201.341992176432, 5962.592666094003, 6215.42253581764, 6218.558732707443, 6228.964100154384, 6204.502084555223, 6181.105312373063, 6206.914072243539, 6216.367111476811, 6222.802355699974, 6248.008998947141, 6217.798015573568], []]
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
CMD: "/opt/conda/bin/python multiproc.py --nproc_per_node 16 main.py -p 1 -j 3 --training-only  --workspace /data/workspace --epochs 2 --prof 100  -b 448 --data-backend dali-gpu --raport-file /data/workspace/./raport_16GPU_448BS_dali-gpu_trainingbench.json --no-checkpoints /data/imagenet --arch resnet50 -c fanin --label-smoothing 0.1 --mixup 0.1" exited with status 1
train.total_ips
[[227.57825988469457, 2119.646071191286, 6260.134693763029, 6224.617347611656, 6236.8221384911785, 6235.943768636739, 6268.782932433463, 6254.138824009086, 6259.797106698289, 6251.091742201267, 6252.900517706253, 6229.546836540958, 6239.803195544499, 6206.331078132451, 6256.054156429492, 6231.702553276385, 6244.659170595355, 6275.987437700853, 6165.362594266528, 6228.720196362081, 6240.898021932673, 6268.956781453672, 6243.7127855711715, 6256.311597279831, 6203.442389332887, 6237.521842021757, 6239.975440896849, 6193.619940291319, 6213.754486831478, 6228.815045567138, 6222.4349768703305, 6243.431421852394, 6206.770555838961, 6223.7198652652205, 6251.901580200171, 6242.764418878874, 6240.929761760319, 6219.569559066087, 6189.143980111009, 6204.876312902954, 6225.66172946431, 6224.989495340825, 6232.057463054464, 6227.37003763999, 6194.980074946127, 6225.948262628298, 6259.689907612395, 6240.385695096356, 6242.249517475525, 6224.488797827572, 6215.013308839676, 6237.9340386101285, 6221.28578950456, 6211.099146600048, 6235.115429995779, 6227.293290348492, 6216.724775754734, 6235.742321775465, 6224.43016284726, 6241.521541950937, 6207.654184055818, 6039.013160087092, 6210.1763746897595, 6205.241621234657, 6219.884805987354, 6223.248677911827, 6207.582407909922, 6230.118385480449, 6234.472827035609, 6228.0021461032275, 6239.896116198065, 6232.6995681700355, 6240.44463106995, 6242.753076523363, 6213.749991952445, 6229.881168644675, 6223.93857454781, 6188.149705376275, 6188.08060846801, 6208.825266858643, 6211.510104085166, 6248.386221585175, 6238.006518367039, 6207.869522452929, 6218.781581551724, 5952.240763389353, 6218.738811343095, 6225.192503767575, 6255.742066289523, 6217.919537771253, 6223.203591953243, 6214.889651949059, 6198.844864246789, 6182.9539139691915, 6217.640493868267, 6227.37003763999, 6208.446074826438, 6194.834876104162, 6239.846255991097, 6233.224202944876], [4071.421810094928, 5899.8444613328875, 6245.385607875499, 6232.851070005101, 6213.990477113677, 6213.907316587967, 6234.766959838432, 6214.563671004716, 6204.643255216111, 6241.487528555568, 6232.724441100306, 6195.797783200244, 6195.489441622754, 6232.392064704186, 6229.104127628716, 6204.9009642590645, 6223.782996263528, 6249.18626609005, 6248.02944960915, 6234.49997659323, 6232.104938128294, 6218.387667663378, 6186.057422029157, 6187.83766707379, 6191.349913399726, 5955.498837143599, 6202.951870792756, 6201.879271811522, 6206.1718949306605, 6225.048140859636, 6222.840673781575, 6237.272738626511, 6208.881364287385, 5945.88963334209, 6234.687767507521, 6247.899931010731, 6243.433690813215, 6236.550451282114, 6247.861303696376, 6221.770199087297, 6205.53076077569, 5952.510930286142, 6204.244408643972, 6214.347867952422, 6218.797339145311, 6228.126325344861, 6212.114287863179, 6214.644601013523, 6226.580082475632, 5984.926504333879, 6238.083529954285, 6164.398063833222, 6193.66013275011, 6237.256887265625, 6230.696818439811, 6219.087743380675, 6203.9173031026685, 6012.692962890763, 6234.785061225112, 6213.70953833378, 6201.0107161355645, 6203.063854493356, 6235.86454640818, 6224.046807507026, 6215.579945159209, 6010.069981815726, 6247.30921252395, 6192.2983456201055, 6210.358213152829, 6234.269212890303, 6225.282733985266, 6210.901547061314, 6210.616397164351, 5972.903803878662, 6215.645159936497, 6231.646042711403, 6233.80547475979, 6212.336675051095, 6187.813151112014, 6169.336720868425, 6209.197772767653, 6233.491076932678, 6228.776653874253, 6243.533526722018, 6215.217915592501, 6243.032110433465, 6226.713232301303, 6219.463733335747, 6201.341992176432, 5962.592666094003, 6215.42253581764, 6218.558732707443, 6228.964100154384, 6204.502084555223, 6181.105312373063, 6206.914072243539, 6216.367111476811, 6222.802355699974, 6248.008998947141, 6217.798015573568], []]=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f52a1050048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-cpu
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 448
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 4; 31.72 GiB total capacity; 26.99 GiB already allocated; 510.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 11; 31.72 GiB total capacity; 26.99 GiB already allocated; 410.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 0; 31.72 GiB total capacity; 26.99 GiB already allocated; 434.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 15; 31.72 GiB total capacity; 26.99 GiB already allocated; 492.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 3; 31.72 GiB total capacity; 26.99 GiB already allocated; 628.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 14; 31.72 GiB total capacity; 26.32 GiB already allocated; 488.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 12; 31.72 GiB total capacity; 26.99 GiB already allocated; 600.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 8; 31.72 GiB total capacity; 26.99 GiB already allocated; 452.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 5; 31.72 GiB total capacity; 26.99 GiB already allocated; 324.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 6; 31.72 GiB total capacity; 26.99 GiB already allocated; 132.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 298, in forward
    out = self.bn1(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 13; 31.72 GiB total capacity; 28.00 GiB already allocated; 64.38 MiB free; 111.31 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    main(args)
  File "main.py", line 282, in main
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    x = self.layer2(x)
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    training, momentum, eps, torch.backends.cudnn.enabled
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 9; 31.72 GiB total capacity; 26.99 GiB already allocated; 422.38 MiB free; 454.32 MiB cached)
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 10; 31.72 GiB total capacity; 26.99 GiB already allocated; 562.31 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 1; 31.72 GiB total capacity; 26.32 GiB already allocated; 498.31 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 686.00 MiB (GPU 7; 31.72 GiB total capacity; 26.99 GiB already allocated; 496.38 MiB free; 454.32 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 460, in forward
    x = self.layer3(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 298, in forward
    out = self.bn1(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 2; 31.72 GiB total capacity; 28.00 GiB already allocated; 52.38 MiB free; 111.31 MiB cached)
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f536dd64048>}
data : /data/imagenet
data_backend : pytorch
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 512
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 5; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 8; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 13; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 9; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 6; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 10; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.31 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 15; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 11; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 12; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 2; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 7; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 4; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 14; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 1; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.31 MiB free; 558.37 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 3; 31.72 GiB total capacity; 30.06 GiB already allocated; 70.38 MiB free; 558.37 MiB cached)
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']

['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '448', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
CMD: "/opt/conda/bin/python multiproc.py --nproc_per_node 16 main.py -p 1 -j 3 --training-only  --workspace /data/workspace --epochs 2 --prof 100  -b 448 --data-backend dali-cpu --raport-file /data/workspace/./raport_16GPU_448BS_dali-cpu_trainingbench.json --no-checkpoints /data/imagenet --arch resnet50 -c fanin --label-smoothing 0.1 --mixup 0.1" exited with status 1
train.total_ips
[[227.57825988469457, 2119.646071191286, 6260.134693763029, 6224.617347611656, 6236.8221384911785, 6235.943768636739, 6268.782932433463, 6254.138824009086, 6259.797106698289, 6251.091742201267, 6252.900517706253, 6229.546836540958, 6239.803195544499, 6206.331078132451, 6256.054156429492, 6231.702553276385, 6244.659170595355, 6275.987437700853, 6165.362594266528, 6228.720196362081, 6240.898021932673, 6268.956781453672, 6243.7127855711715, 6256.311597279831, 6203.442389332887, 6237.521842021757, 6239.975440896849, 6193.619940291319, 6213.754486831478, 6228.815045567138, 6222.4349768703305, 6243.431421852394, 6206.770555838961, 6223.7198652652205, 6251.901580200171, 6242.764418878874, 6240.929761760319, 6219.569559066087, 6189.143980111009, 6204.876312902954, 6225.66172946431, 6224.989495340825, 6232.057463054464, 6227.37003763999, 6194.980074946127, 6225.948262628298, 6259.689907612395, 6240.385695096356, 6242.249517475525, 6224.488797827572, 6215.013308839676, 6237.9340386101285, 6221.28578950456, 6211.099146600048, 6235.115429995779, 6227.293290348492, 6216.724775754734, 6235.742321775465, 6224.43016284726, 6241.521541950937, 6207.654184055818, 6039.013160087092, 6210.1763746897595, 6205.241621234657, 6219.884805987354, 6223.248677911827, 6207.582407909922, 6230.118385480449, 6234.472827035609, 6228.0021461032275, 6239.896116198065, 6232.6995681700355, 6240.44463106995, 6242.753076523363, 6213.749991952445, 6229.881168644675, 6223.93857454781, 6188.149705376275, 6188.08060846801, 6208.825266858643, 6211.510104085166, 6248.386221585175, 6238.006518367039, 6207.869522452929, 6218.781581551724, 5952.240763389353, 6218.738811343095, 6225.192503767575, 6255.742066289523, 6217.919537771253, 6223.203591953243, 6214.889651949059, 6198.844864246789, 6182.9539139691915, 6217.640493868267, 6227.37003763999, 6208.446074826438, 6194.834876104162, 6239.846255991097, 6233.224202944876], [4071.421810094928, 5899.8444613328875, 6245.385607875499, 6232.851070005101, 6213.990477113677, 6213.907316587967, 6234.766959838432, 6214.563671004716, 6204.643255216111, 6241.487528555568, 6232.724441100306, 6195.797783200244, 6195.489441622754, 6232.392064704186, 6229.104127628716, 6204.9009642590645, 6223.782996263528, 6249.18626609005, 6248.02944960915, 6234.49997659323, 6232.104938128294, 6218.387667663378, 6186.057422029157, 6187.83766707379, 6191.349913399726, 5955.498837143599, 6202.951870792756, 6201.879271811522, 6206.1718949306605, 6225.048140859636, 6222.840673781575, 6237.272738626511, 6208.881364287385, 5945.88963334209, 6234.687767507521, 6247.899931010731, 6243.433690813215, 6236.550451282114, 6247.861303696376, 6221.770199087297, 6205.53076077569, 5952.510930286142, 6204.244408643972, 6214.347867952422, 6218.797339145311, 6228.126325344861, 6212.114287863179, 6214.644601013523, 6226.580082475632, 5984.926504333879, 6238.083529954285, 6164.398063833222, 6193.66013275011, 6237.256887265625, 6230.696818439811, 6219.087743380675, 6203.9173031026685, 6012.692962890763, 6234.785061225112, 6213.70953833378, 6201.0107161355645, 6203.063854493356, 6235.86454640818, 6224.046807507026, 6215.579945159209, 6010.069981815726, 6247.30921252395, 6192.2983456201055, 6210.358213152829, 6234.269212890303, 6225.282733985266, 6210.901547061314, 6210.616397164351, 5972.903803878662, 6215.645159936497, 6231.646042711403, 6233.80547475979, 6212.336675051095, 6187.813151112014, 6169.336720868425, 6209.197772767653, 6233.491076932678, 6228.776653874253, 6243.533526722018, 6215.217915592501, 6243.032110433465, 6226.713232301303, 6219.463733335747, 6201.341992176432, 5962.592666094003, 6215.42253581764, 6218.558732707443, 6228.964100154384, 6204.502084555223, 6181.105312373063, 6206.914072243539, 6216.367111476811, 6222.802355699974, 6248.008998947141, 6217.798015573568], []]
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'pytorch', '--raport-file', '/data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
CMD: "/opt/conda/bin/python multiproc.py --nproc_per_node 16 main.py -p 1 -j 3 --training-only  --workspace /data/workspace --epochs 2 --prof 100  -b 512 --data-backend pytorch --raport-file /data/workspace/./raport_16GPU_512BS_pytorch_trainingbench.json --no-checkpoints /data/imagenet --arch resnet50 -c fanin --label-smoothing 0.1 --mixup 0.1" exited with status 1
train.total_ips
[[227.57825988469457, 2119.646071191286, 6260.134693763029, 6224.617347611656, 6236.8221384911785, 6235.943768636739, 6268.782932433463, 6254.138824009086, 6259.797106698289, 6251.091742201267, 6252.900517706253, 6229.546836540958, 6239.803195544499, 6206.331078132451, 6256.054156429492, 6231.702553276385, 6244.659170595355, 6275.987437700853, 6165.362594266528, 6228.720196362081, 6240.898021932673, 6268.956781453672, 6243.7127855711715, 6256.311597279831, 6203.442389332887, 6237.521842021757, 6239.975440896849, 6193.619940291319, 6213.754486831478, 6228.815045567138, 6222.4349768703305, 6243.431421852394, 6206.770555838961, 6223.7198652652205, 6251.901580200171, 6242.764418878874, 6240.929761760319, 6219.569559066087, 6189.143980111009, 6204.876312902954, 6225.66172946431, 6224.989495340825, 6232.057463054464, 6227.37003763999, 6194.980074946127, 6225.948262628298, 6259.689907612395, 6240.385695096356, 6242.249517475525, 6224.488797827572, 6215.013308839676, 6237.9340386101285, 6221.28578950456, 6211.099146600048, 6235.115429995779, 6227.293290348492, 6216.724775754734, 6235.742321775465, 6224.43016284726, 6241.521541950937, 6207.654184055818, 6039.013160087092, 6210.1763746897595, 6205.241621234657, 6219.884805987354, 6223.248677911827, 6207.582407909922, 6230.118385480449, 6234.472827035609, 6228.0021461032275, 6239.896116198065, 6232.6995681700355, 6240.44463106995, 6242.753076523363, 6213.749991952445, 6229.881168644675, 6223.93857454781, 6188.149705376275, 6188.08060846801, 6208.825266858643, 6211.510104085166, 6248.386221585175, 6238.006518367039, 6207.869522452929, 6218.781581551724, 5952.240763389353, 6218.738811343095, 6225.192503767575, 6255.742066289523, 6217.919537771253, 6223.203591953243, 6214.889651949059, 6198.844864246789, 6182.9539139691915, 6217.640493868267, 6227.37003763999, 6208.446074826438, 6194.834876104162, 6239.846255991097, 6233.224202944876], [4071.421810094928, 5899.8444613328875, 6245.385607875499, 6232.851070005101, 6213.990477113677, 6213.907316587967, 6234.766959838432, 6214.563671004716, 6204.643255216111, 6241.487528555568, 6232.724441100306, 6195.797783200244, 6195.489441622754, 6232.392064704186, 6229.104127628716, 6204.9009642590645, 6223.782996263528, 6249.18626609005, 6248.02944960915, 6234.49997659323, 6232.104938128294, 6218.387667663378, 6186.057422029157, 6187.83766707379, 6191.349913399726, 5955.498837143599, 6202.951870792756, 6201.879271811522, 6206.1718949306605, 6225.048140859636, 6222.840673781575, 6237.272738626511, 6208.881364287385, 5945.88963334209, 6234.687767507521, 6247.899931010731, 6243.433690813215, 6236.550451282114, 6247.861303696376, 6221.770199087297, 6205.53076077569, 5952.510930286142, 6204.244408643972, 6214.347867952422, 6218.797339145311, 6228.126325344861, 6212.114287863179, 6214.644601013523, 6226.580082475632, 5984.926504333879, 6238.083529954285, 6164.398063833222, 6193.66013275011, 6237.256887265625, 6230.696818439811, 6219.087743380675, 6203.9173031026685, 6012.692962890763, 6234.785061225112, 6213.70953833378, 6201.0107161355645, 6203.063854493356, 6235.86454640818, 6224.046807507026, 6215.579945159209, 6010.069981815726, 6247.30921252395, 6192.2983456201055, 6210.358213152829, 6234.269212890303, 6225.282733985266, 6210.901547061314, 6210.616397164351, 5972.903803878662, 6215.645159936497, 6231.646042711403, 6233.80547475979, 6212.336675051095, 6187.813151112014, 6169.336720868425, 6209.197772767653, 6233.491076932678, 6228.776653874253, 6243.533526722018, 6215.217915592501, 6243.032110433465, 6226.713232301303, 6219.463733335747, 6201.341992176432, 5962.592666094003, 6215.42253581764, 6218.558732707443, 6228.964100154384, 6204.502084555223, 6181.105312373063, 6206.914072243539, 6216.367111476811, 6222.802355699974, 6248.008998947141, 6217.798015573568], []]=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f4a343a3048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-gpu
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 512
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 311, in forward
    residual = self.downsample(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 7; 31.72 GiB total capacity; 24.69 GiB already allocated; 582.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 5; 31.72 GiB total capacity; 26.23 GiB already allocated; 2.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 10; 31.72 GiB total capacity; 26.23 GiB already allocated; 146.31 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 1; 31.72 GiB total capacity; 26.23 GiB already allocated; 118.31 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 31.72 GiB total capacity; 26.23 GiB already allocated; 4.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 3; 31.72 GiB total capacity; 26.23 GiB already allocated; 232.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 11; 31.72 GiB total capacity; 26.23 GiB already allocated; 2.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 6; 31.72 GiB total capacity; 25.46 GiB already allocated; 464.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 12; 31.72 GiB total capacity; 25.46 GiB already allocated; 2.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 14; 31.72 GiB total capacity; 25.46 GiB already allocated; 10.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    main(args)
  File "main.py", line 282, in main
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 4; 31.72 GiB total capacity; 26.23 GiB already allocated; 68.38 MiB free; 16.34 MiB cached)
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 15; 31.72 GiB total capacity; 26.23 GiB already allocated; 52.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 8; 31.72 GiB total capacity; 26.23 GiB already allocated; 2.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    main(args)
  File "main.py", line 282, in main
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    result = self.forward(*input, **kwargs)
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 13; 31.72 GiB total capacity; 26.23 GiB already allocated; 266.38 MiB free; 16.34 MiB cached)
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 2; 31.72 GiB total capacity; 26.23 GiB already allocated; 212.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 306, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 9; 31.72 GiB total capacity; 25.46 GiB already allocated; 638.38 MiB free; 16.34 MiB cached)
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
=> creating model '('resnet50', 'fanin')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_in', 'nonlinearity': 'relu', 'bn': True, 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7f89deb2e048>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
data : /data/imagenet
data_backend : dali-cpu
arch : resnet50
model_config : fanin
workers : 3
epochs : 2
start_epoch : 0
batch_size : 512
optimizer_batch_size : -1
lr : 0.1
lr_schedule : step
warmup : 0
label_smoothing : 0.1
mixup : 0.1
true_weight_decay : False
momentum : 0.9
weight_decay : 0.0001
bn_weight_decay : False
nesterov : False
print_freq : 1
resume : 
pretrained_weights : 
fp16 : False
static_loss_scale : 1
dynamic_loss_scale : False
prof : 100
local_rank : 0
seed : None
gather_checkpoints : False
raport_file : /data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json
final_weights : model.pth.tar
evaluate : False
training_only : True
save_checkpoints : False
workspace : /data/workspace
distributed : True
gpu : 0
world_size : 16
 ! Weight decay NOT applied to BN parameters 
98
63
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 14; 31.72 GiB total capacity; 26.23 GiB already allocated; 530.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 303, in forward
    out = self.bn2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 3; 31.72 GiB total capacity; 27.57 GiB already allocated; 108.38 MiB free; 42.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 298, in forward
    out = self.bn1(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 5; 31.72 GiB total capacity; 27.18 GiB already allocated; 196.38 MiB free; 16.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 301, in forward
    out = self.conv2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 8; 31.72 GiB total capacity; 27.37 GiB already allocated; 122.38 MiB free; 16.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 12; 31.72 GiB total capacity; 26.23 GiB already allocated; 506.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 301, in forward
    out = self.conv2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 31.72 GiB total capacity; 27.37 GiB already allocated; 102.38 MiB free; 16.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 303, in forward
    out = self.bn2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 2; 31.72 GiB total capacity; 27.57 GiB already allocated; 132.38 MiB free; 42.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 308, in forward
    out = self.bn3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 7; 31.72 GiB total capacity; 26.23 GiB already allocated; 338.38 MiB free; 16.34 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 303, in forward
    out = self.bn2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 10; 31.72 GiB total capacity; 27.57 GiB already allocated; 32.31 MiB free; 42.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 301, in forward
    out = self.conv2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 15; 31.72 GiB total capacity; 27.37 GiB already allocated; 178.38 MiB free; 16.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 301, in forward
    out = self.conv2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 11; 31.72 GiB total capacity; 27.37 GiB already allocated; 86.38 MiB free; 16.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 298, in forward
    out = self.bn1(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 6; 31.72 GiB total capacity; 27.18 GiB already allocated; 24.38 MiB free; 16.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 298, in forward
    out = self.bn1(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 9; 31.72 GiB total capacity; 27.18 GiB already allocated; 166.38 MiB free; 16.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 301, in forward
    out = self.conv2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 339, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 4; 31.72 GiB total capacity; 27.37 GiB already allocated; 180.38 MiB free; 16.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 303, in forward
    out = self.bn2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 13; 31.72 GiB total capacity; 27.57 GiB already allocated; 186.38 MiB free; 42.33 MiB cached)
Traceback (most recent call last):
  File "main.py", line 297, in <module>
    main(args)
  File "main.py", line 282, in main
    save_checkpoints=args.save_checkpoints and not args.evaluate, checkpoint_dir=args.workspace)
  File "/workspace/rn50/image_classification/training.py", line 335, in train_loop
    train(train_loader, model_and_loss, optimizer, lr_scheduler, fp16, logger, epoch, prof = prof, register_metrics=epoch==start_epoch, batch_size_multiplier=batch_size_multiplier)
  File "/workspace/rn50/image_classification/training.py", line 227, in train
    loss, prec1, prec5 = step(input, target, optimizer_step = optimizer_step)
  File "/workspace/rn50/image_classification/training.py", line 167, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/training.py", line 49, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 473, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 459, in forward
    x = self.layer2(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 97, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/rn50/image_classification/resnet.py", line 303, in forward
    out = self.bn2(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 491, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 77, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 1671, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 1; 31.72 GiB total capacity; 27.57 GiB already allocated; 8.31 MiB free; 42.33 MiB cached)
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=1', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=2', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=3', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=4', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=5', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=6', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=7', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=8', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=9', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=10', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=11', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=12', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=13', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=14', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=15', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']

['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-gpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
CMD: "/opt/conda/bin/python multiproc.py --nproc_per_node 16 main.py -p 1 -j 3 --training-only  --workspace /data/workspace --epochs 2 --prof 100  -b 512 --data-backend dali-gpu --raport-file /data/workspace/./raport_16GPU_512BS_dali-gpu_trainingbench.json --no-checkpoints /data/imagenet --arch resnet50 -c fanin --label-smoothing 0.1 --mixup 0.1" exited with status 1
train.total_ips
[[227.57825988469457, 2119.646071191286, 6260.134693763029, 6224.617347611656, 6236.8221384911785, 6235.943768636739, 6268.782932433463, 6254.138824009086, 6259.797106698289, 6251.091742201267, 6252.900517706253, 6229.546836540958, 6239.803195544499, 6206.331078132451, 6256.054156429492, 6231.702553276385, 6244.659170595355, 6275.987437700853, 6165.362594266528, 6228.720196362081, 6240.898021932673, 6268.956781453672, 6243.7127855711715, 6256.311597279831, 6203.442389332887, 6237.521842021757, 6239.975440896849, 6193.619940291319, 6213.754486831478, 6228.815045567138, 6222.4349768703305, 6243.431421852394, 6206.770555838961, 6223.7198652652205, 6251.901580200171, 6242.764418878874, 6240.929761760319, 6219.569559066087, 6189.143980111009, 6204.876312902954, 6225.66172946431, 6224.989495340825, 6232.057463054464, 6227.37003763999, 6194.980074946127, 6225.948262628298, 6259.689907612395, 6240.385695096356, 6242.249517475525, 6224.488797827572, 6215.013308839676, 6237.9340386101285, 6221.28578950456, 6211.099146600048, 6235.115429995779, 6227.293290348492, 6216.724775754734, 6235.742321775465, 6224.43016284726, 6241.521541950937, 6207.654184055818, 6039.013160087092, 6210.1763746897595, 6205.241621234657, 6219.884805987354, 6223.248677911827, 6207.582407909922, 6230.118385480449, 6234.472827035609, 6228.0021461032275, 6239.896116198065, 6232.6995681700355, 6240.44463106995, 6242.753076523363, 6213.749991952445, 6229.881168644675, 6223.93857454781, 6188.149705376275, 6188.08060846801, 6208.825266858643, 6211.510104085166, 6248.386221585175, 6238.006518367039, 6207.869522452929, 6218.781581551724, 5952.240763389353, 6218.738811343095, 6225.192503767575, 6255.742066289523, 6217.919537771253, 6223.203591953243, 6214.889651949059, 6198.844864246789, 6182.9539139691915, 6217.640493868267, 6227.37003763999, 6208.446074826438, 6194.834876104162, 6239.846255991097, 6233.224202944876], [4071.421810094928, 5899.8444613328875, 6245.385607875499, 6232.851070005101, 6213.990477113677, 6213.907316587967, 6234.766959838432, 6214.563671004716, 6204.643255216111, 6241.487528555568, 6232.724441100306, 6195.797783200244, 6195.489441622754, 6232.392064704186, 6229.104127628716, 6204.9009642590645, 6223.782996263528, 6249.18626609005, 6248.02944960915, 6234.49997659323, 6232.104938128294, 6218.387667663378, 6186.057422029157, 6187.83766707379, 6191.349913399726, 5955.498837143599, 6202.951870792756, 6201.879271811522, 6206.1718949306605, 6225.048140859636, 6222.840673781575, 6237.272738626511, 6208.881364287385, 5945.88963334209, 6234.687767507521, 6247.899931010731, 6243.433690813215, 6236.550451282114, 6247.861303696376, 6221.770199087297, 6205.53076077569, 5952.510930286142, 6204.244408643972, 6214.347867952422, 6218.797339145311, 6228.126325344861, 6212.114287863179, 6214.644601013523, 6226.580082475632, 5984.926504333879, 6238.083529954285, 6164.398063833222, 6193.66013275011, 6237.256887265625, 6230.696818439811, 6219.087743380675, 6203.9173031026685, 6012.692962890763, 6234.785061225112, 6213.70953833378, 6201.0107161355645, 6203.063854493356, 6235.86454640818, 6224.046807507026, 6215.579945159209, 6010.069981815726, 6247.30921252395, 6192.2983456201055, 6210.358213152829, 6234.269212890303, 6225.282733985266, 6210.901547061314, 6210.616397164351, 5972.903803878662, 6215.645159936497, 6231.646042711403, 6233.80547475979, 6212.336675051095, 6187.813151112014, 6169.336720868425, 6209.197772767653, 6233.491076932678, 6228.776653874253, 6243.533526722018, 6215.217915592501, 6243.032110433465, 6226.713232301303, 6219.463733335747, 6201.341992176432, 5962.592666094003, 6215.42253581764, 6218.558732707443, 6228.964100154384, 6204.502084555223, 6181.105312373063, 6206.914072243539, 6216.367111476811, 6222.802355699974, 6248.008998947141, 6217.798015573568], []]
['/opt/conda/bin/python', 'multiproc.py', '--nproc_per_node', '16', 'main.py', '-p', '1', '-j', '3', '--training-only', '--workspace', '/data/workspace', '--epochs', '2', '--prof', '100', '-b', '512', '--data-backend', 'dali-cpu', '--raport-file', '/data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json', '--no-checkpoints', '/data/imagenet', '--arch', 'resnet50', '-c', 'fanin', '--label-smoothing', '0.1', '--mixup', '0.1']
CMD: "/opt/conda/bin/python multiproc.py --nproc_per_node 16 main.py -p 1 -j 3 --training-only  --workspace /data/workspace --epochs 2 --prof 100  -b 512 --data-backend dali-cpu --raport-file /data/workspace/./raport_16GPU_512BS_dali-cpu_trainingbench.json --no-checkpoints /data/imagenet --arch resnet50 -c fanin --label-smoothing 0.1 --mixup 0.1" exited with status 1
train.total_ips
[[227.57825988469457, 2119.646071191286, 6260.134693763029, 6224.617347611656, 6236.8221384911785, 6235.943768636739, 6268.782932433463, 6254.138824009086, 6259.797106698289, 6251.091742201267, 6252.900517706253, 6229.546836540958, 6239.803195544499, 6206.331078132451, 6256.054156429492, 6231.702553276385, 6244.659170595355, 6275.987437700853, 6165.362594266528, 6228.720196362081, 6240.898021932673, 6268.956781453672, 6243.7127855711715, 6256.311597279831, 6203.442389332887, 6237.521842021757, 6239.975440896849, 6193.619940291319, 6213.754486831478, 6228.815045567138, 6222.4349768703305, 6243.431421852394, 6206.770555838961, 6223.7198652652205, 6251.901580200171, 6242.764418878874, 6240.929761760319, 6219.569559066087, 6189.143980111009, 6204.876312902954, 6225.66172946431, 6224.989495340825, 6232.057463054464, 6227.37003763999, 6194.980074946127, 6225.948262628298, 6259.689907612395, 6240.385695096356, 6242.249517475525, 6224.488797827572, 6215.013308839676, 6237.9340386101285, 6221.28578950456, 6211.099146600048, 6235.115429995779, 6227.293290348492, 6216.724775754734, 6235.742321775465, 6224.43016284726, 6241.521541950937, 6207.654184055818, 6039.013160087092, 6210.1763746897595, 6205.241621234657, 6219.884805987354, 6223.248677911827, 6207.582407909922, 6230.118385480449, 6234.472827035609, 6228.0021461032275, 6239.896116198065, 6232.6995681700355, 6240.44463106995, 6242.753076523363, 6213.749991952445, 6229.881168644675, 6223.93857454781, 6188.149705376275, 6188.08060846801, 6208.825266858643, 6211.510104085166, 6248.386221585175, 6238.006518367039, 6207.869522452929, 6218.781581551724, 5952.240763389353, 6218.738811343095, 6225.192503767575, 6255.742066289523, 6217.919537771253, 6223.203591953243, 6214.889651949059, 6198.844864246789, 6182.9539139691915, 6217.640493868267, 6227.37003763999, 6208.446074826438, 6194.834876104162, 6239.846255991097, 6233.224202944876], [4071.421810094928, 5899.8444613328875, 6245.385607875499, 6232.851070005101, 6213.990477113677, 6213.907316587967, 6234.766959838432, 6214.563671004716, 6204.643255216111, 6241.487528555568, 6232.724441100306, 6195.797783200244, 6195.489441622754, 6232.392064704186, 6229.104127628716, 6204.9009642590645, 6223.782996263528, 6249.18626609005, 6248.02944960915, 6234.49997659323, 6232.104938128294, 6218.387667663378, 6186.057422029157, 6187.83766707379, 6191.349913399726, 5955.498837143599, 6202.951870792756, 6201.879271811522, 6206.1718949306605, 6225.048140859636, 6222.840673781575, 6237.272738626511, 6208.881364287385, 5945.88963334209, 6234.687767507521, 6247.899931010731, 6243.433690813215, 6236.550451282114, 6247.861303696376, 6221.770199087297, 6205.53076077569, 5952.510930286142, 6204.244408643972, 6214.347867952422, 6218.797339145311, 6228.126325344861, 6212.114287863179, 6214.644601013523, 6226.580082475632, 5984.926504333879, 6238.083529954285, 6164.398063833222, 6193.66013275011, 6237.256887265625, 6230.696818439811, 6219.087743380675, 6203.9173031026685, 6012.692962890763, 6234.785061225112, 6213.70953833378, 6201.0107161355645, 6203.063854493356, 6235.86454640818, 6224.046807507026, 6215.579945159209, 6010.069981815726, 6247.30921252395, 6192.2983456201055, 6210.358213152829, 6234.269212890303, 6225.282733985266, 6210.901547061314, 6210.616397164351, 5972.903803878662, 6215.645159936497, 6231.646042711403, 6233.80547475979, 6212.336675051095, 6187.813151112014, 6169.336720868425, 6209.197772767653, 6233.491076932678, 6228.776653874253, 6243.533526722018, 6215.217915592501, 6243.032110433465, 6226.713232301303, 6219.463733335747, 6201.341992176432, 5962.592666094003, 6215.42253581764, 6218.558732707443, 6228.964100154384, 6204.502084555223, 6181.105312373063, 6206.914072243539, 6216.367111476811, 6222.802355699974, 6248.008998947141, 6217.798015573568], []]
 train.total_ips |      16 p |      16 d-g |      16 d-c |
----------------------------------------------------------
             224 |    6157.0 |    6108.9 |    6163.1 |
             256 |    6198.6 |    6130.3 |    6198.5 |
             448 |      -1.0 |      -1.0 |      -1.0 |
             512 |      -1.0 |      -1.0 |      -1.0 |
